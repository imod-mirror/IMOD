#!/usr/bin/env python
# batchruntomo - run one or more data sets in batch mode
#
# Author: David Mastronarde
#
# $Id$
#

progname = 'batchruntomo'
prefix = 'ERROR: ' + progname + ' - '

# Index of batch directives in allDirectives array
BatInd = 3

# Variables that need to be global, probably superfluous but here as an FYI
global datasetDir, dualAxis, setName, scanHeader, ifMontage, defocus, pixelSize
global fidSizeNm, fidSizePix, montFrameData, lightBeads, numSurfaces, haveAaxisAFSbound
global rawXsize, rawYsize, zsize, fiducialless, coarseBinning
global xtiltNeeded, fidThickness, fidIncShift, reconThickness, didLocalAlign, madeZfactors
global aliBinning, aliXunbinned, aliYunbinned, patchTrack, totalDelTilt, latestMessages
global suppressAbort, absDirectiveFile, userTemplateDir, summaryMessage, logFile
global finalRetVal, correctCTF, eraseGold, axisLet, axisNum, useVolMatch, nxRecA, nyRecA
global finishSetAndQuit, finalAlignResid

# Print a string to both standard out and a log file if one is defined
def prnLog(string, end  = '\n', flush = False):
   prnstr(string, end = end, flush = flush)
   if logFile:
      prnstr(string, file = logFile, end = end, flush = flush)


# Close the log file
def closeLogFile():
   global logFile
   if not logFile:
      return
   prnstr('Batchruntomo finished with data set, ' + datetime.datetime.now().ctime(),
          file = logFile)
   logFile.close()
   logFile = None
   
      
# Send an email if there is an address
def sendEmail(subject, message):
   if not emailAddress:
      return
   try:
      msg = MIMEText(message)
      msg['Subject'] = subject
      msg['From'] = 'batchruntomo'
      msg['To'] = emailAddress
      s = smtplib.SMTP(SMTPserver)
      s.sendmail(emailAddress, [emailAddress], msg.as_string())
      s.quit()
   except Exception:
      prnLog('WARNING: Failed to send email notification')
   

# Abort either an axis or a data set with the error string
def abortSet(errString):
   global summaryMessage, finalRetVal
   if suppressAbort:
      return
   abortStr = ['ABORT SET: ', 'ABORT AXIS: ', 'ABORT AXIS AND SET: ']
   prnLog(abortStr[axisNum] + errString)
   prnLog('', flush = True)
   if dualAxis and axisNum:
      message = 'Batchruntomo aborted axis ' + axisLet.upper() + ' of'
   elif dualAxis:
      message = 'Batchruntomo aborted combine of'
   else:
      message = 'Batchruntomo aborted'
   message += ' dataset ' + setName + ' after error:\n' + errString + '\n'
   sendEmail('Batchruntomo error on ' + setName, message)
   summaryMessage += message
   finalRetVal += 1
   if exitOnError:
      sys.exit(1)


# Report the error from running a program and then abort
def reportImodError(abortText = None):
   errStrings =  getErrStrings()
   num = len(errStrings)
   for ind in range(num):
      l = errStrings[ind]
      if ind == num - 1:
         l = 'ERROR: ' + l
      prnLog(l, end = '')
   if abortText:
      abortSet(abortText)


# Get elapsed time and break into minutes, seconds, and fraction of seconds
def elapsedComponents(startTime):
   used = time.time() - startTime
   minutes = int(used / 60.)
   used -= 60 * minutes
   seconds = int(used)
   frac = int(round((used - seconds) * 10))
   return (minutes, seconds, frac)


# Test whether a value returned by lookupDirective is a string and abort with message
def testDirectiveValue(val, directive, dtype):
   if isinstance(val, str):
      abortSet('An error occurred converting the value of the directive ' + directive + \
                  ' to a ', + dtype)
      return 1
   return 0


# Print lines starting with tags in a log file.  Tags is an array of duples, the first
# element of each is the tag itself, the second is the sum of 1 if it is used for
# multiline messages and 2 if it should be stripped and 4 if it is not at start of a line
def printTaggedMessages(logfile, tags):
   global latestMessages
   blankNeeded = ('ERROR', 'INFO', 'WARNING')
   needFinalBlank = False
   needBlank = ''
   latestMessages = []
   anyError = False
   if isinstance(logfile, str):
      loglines = readTextFile(logfile, None, True)
      if isinstance(loglines, str):
         prnLog('WARNING: Error ' + loglines)
         prnLog(' ')
         return
   else:
      loglines = logfile
      
   readingMulti = False
   for l in loglines:
      if readingMulti:
         prnLog(l)
         needFinalBlank = True
         latestMessages.append(l)
         if l.strip() == '':
            readingMulti = False
            needBlank = ''
            needFinalBlank = False
            
      else:
         for tag in tags:
            if tag[1] & 4:
               match = tag[0] in l
            else:
               match = l.startswith(tag[0])
            if match:
               # Suppress uninformative vmstopy output if there is already a message
               if not anyError or not (l.startswith('ERROR:') and \
                                          l.endswith('exited with status 1')):
                  if tag[0].startswith('ERROR'):
                     anyError = True

                  # If we needed a blank for a particular kind of message, and this is
                  # not another of that type, put the blank out
                  if needBlank and not tag[0].startswith(needBlank):
                     prnlog('')
                     needBlank = ''
                     needFinalBlank = False
                     
                  # Print message one way or the other
                  latestMessages.append(l)
                  if tag[1] & 2:
                     prnLog(l[len(tag[0]):].lstrip())
                  else:
                     prnLog(l)
                  needFinalBlank = True

                  # See if a blank is needed after contiguous lines of this type
                  if not needBlank:
                     for need in blankNeeded:
                        if tag[0].startswith(need):
                           needBlank = need
                           break
                  
               if tag[1] & 1:
                  readingMulti = True
               break

   if needFinalBlank:
      prnLog(' ')
            

# Look for a tag in a set of lines, and get the value after the separator
def findTaggedValue(lines, tag, separator, valType):
   for l in lines:
      ind = l.find(separator)
      if ind > 0 and tag in l and ind < len(l) - 1:
         valAll = l[ind + 1:].strip()
         if valType == STRING_VALUE:
            return valAll
         vsplit = valAll.split()
         if not len(vsplit):
            return None
         try:
            if valType == INT_VALUE:
               value = int(vsplit[0])
            else:
               value = float(vsplit[0])
            return value
         except:
            return None
   return None


# Write a text file and report a returned error
def writeTextFileReportErr(filename, lines):
   err = writeTextFile(filename, lines, True)
   if err:
      abortSet('Error ' + err)
   return err


# Read a text file and report a returned error and return [] on error
def readTextFileReportErr(filename, message = None):
   lines = readTextFile(filename, message, True)
   if isinstance(lines, str):
      abortSet('Error ' + lines)
      return []
   if len(lines) == 0:
      abortSet('File ' + filename + ' is empty')
   return lines


# Check existence of stack, rename if necessary
def checkRenameStack(stack):
   if not os.path.exists(stack + 'st'):
      if not os.path.exists(stack + altExtension):
         abortSet('Stack file does not exist with either name: ' + stack + 'st  or  ' +\
                     stack + altExtension)
         return 1
      try:
         os.rename(stack + altExtension, stack + 'st')
         prnLog('Renamed stack from ' + stack + altExtension + ' to: ' + stack + 'st')
      except OSError:
         abortSet('Error renaming stack from ' + stack + altExtension + ' to ' + stack +\
                     'st')
         return 1


# Delivery some associated file with the given source and destination names
def deliverAncillary(source, dest, typeName, fullExt):
   if os.path.exists(source) and not os.path.exists(dest):
      try:
         os.rename(source, dest)
      except OSError:
         abortSet(fmtstr('Error moving {} file {}.{} from {} to {}', setName, fullExt,
                         deliverFromDir, datasetDir))
         return 1
   return 0
   
      
# Move a stack to the dataset directory
def deliverStack(axis):
   stackRoot = setName + axis
   sourceRoot = os.path.join(deliverFromDir, stackRoot + '.')
   source = sourceRoot + 'st'
   ext = 'st'
   destRoot = os.path.join(datasetDir, stackRoot + '.')
   dest = destRoot + 'st'

   # Etomo may change the current dir after delivery, so if they match, skip
   if deliverFromDir == datasetDir:
      return 0

   # Look for either extension and change it during the move
   renaming = False
   skipIt = False
   if not os.path.exists(source):
      ext = altExtension
      source = sourceRoot + altExtension
      if not os.path.exists(source):
         if os.path.exists(dest):
            prnLog('Stack file is already delivered to dataset directory; assuming ' + \
                      'associated files are too')
            return 0
         abortSet('Stack file ' + stackRoot + ' does not exist in ' + \
                     deliverFromDir + ' with either extension .st or .' + altExtension)
         return 1
      renaming = True

   if os.path.exists(dest):
      abortSet('Stack file ' + stackRoot + '.st already exists in ' + datasetDir)
      return 1
   try:
      os.rename(source, dest)
      prnLog('Delivered stack ' + source + ' to: ' + dest)
      if renaming:
         prnLog('Renamed stack from ' + stackRoot + '.' + altExtension + ' to: ' + \
                   stackRoot + '.st')
   except OSError:
      abortSet('Error moving/renaming stack file from ' + source + ' to ' + dest)
      return 1

   # Move .mdoc, .log, .rawtlt files also
   if deliverAncillary(source + '.mdoc', dest + '.mdoc', 'metadata', ext + '.mdoc'):
      return 1
   if deliverAncillary(sourceRoot + 'log', destRoot + 'log', 'tilt series log', 'log'):
      return 1
   if deliverAncillary(sourceRoot + 'rawtlt', destRoot + 'rawtlt', 'raw tilt angle',
                       'rawtlt'):
      return 1

   return 0
   

# Print out errors from directive file reading or validation
def printDirectiveErrors(errors):
   if errors:
      prnLog('ERROR: Incorrect directive(s) as listed below:')
      for l in errors:
         prnLog(l)
      prnLog('')
      abortSet('Bad directives')
   return len(errors)
   

# Return an absolute path to a template file of given type; if the path is already
# absolute, it returns that and 0; otherwise if it is not just a filename, it returns
# None and -1; otherwise it looks for it in the proper places and returns the
# path and 1, or None and -2 if it cannot be found
def absTemplatePath(template, index):
   global userTemplateDir
   if imodIsAbsPath(template):
      return (template, 0)
   if os.path.dirname(template):
      return (None, -1)

   # For scope template, just look up in the ImodCalib
   errval = (None, -2)
   if index == 0:
      if 'IMOD_CALIB_DIR' not in os.environ:
         return errval
      fullPath = os.path.join(os.environ['IMOD_CALIB_DIR'], 'ScopeTemplate', template)
      if os.path.exists(fullPath):
         return (fullPath, 1)
      return errval

   # For system template, look it up in ImodCalib then in IMOD
   if index == 1:
      for rootdir in ('IMOD_CALIB_DIR', 'IMOD_DIR'):
         if rootdir in os.environ:
            fullPath = os.path.join(os.environ[rootdir], 'SystemTemplate',
                                    template)
            if os.path.exists(fullPath):
               return (fullPath, 1)
      return errval

   # For user template, we need to know the directory from .etomo if not the default
   if not userTemplateDir:
      if 'HOME' not in os.environ:
         return errval
      dirpath = os.path.join(os.environ['HOME'], '.etomotemplate')
      if os.path.exists(dirpath):
         userTemplateDir = dirpath
      dotEtomo = os.path.join(os.environ['HOME'], '.etomo')
      if os.path.exists(dotEtomo):
         etomoLines = readTextFile(dotEtomo, None, True)
         if not isinstance(etomoLines, str) and len(etomoLines) > 0:
            defsTempl = optionValue(etomoLines, 'Defaults.UserTemplateDir', STRING_VALUE,
                                    otherSep = '=')
            if defsTempl:
               userTemplateDir = defsTempl

   # Now given the directory, look up the user template file
   if not userTemplateDir or not os.path.exists(userTemplateDir):
      return errval
   fullPath = os.path.join(userTemplateDir, template)
   if os.path.exists(fullPath):
      return (fullPath, 1)
   return errval


# Read a directive or template file and convert to a dictionary, skipping comment
# lines and lines without an =
def readDirectiveOrTemplate(filename, index):
   global absDirectiveFile
   directLines = readTextFile(filename, 'directive/template file', True)
   if isinstance(directLines, str):
      abortSet('Error ' + directLines)
      return 1

   # For the batch file, find existing lines of various things
   if index == BatInd:
      rewriteBatch = False
      nodi = (-1, '')
      lineNumDict = {rootNameText : nodi, dataDirText : nodi, scopeTmplText : nodi,
                  sysTmplText : nodi, userTmplText : nodi}

      # Add raw boundary model variations if doing delivery
      if deliverDir:
         for operation in (patchTrackText, autoSeedText):
            for axlet in ('.a.', '.b.', '.any.'):
               direc = operation + axlet + 'rawBoundaryModel'
               lineNumDict[direc] = nodi

      # Find lines
      for ind in range(len(directLines)):
         line = directLines[ind].lstrip()
         lsplit = line.split('=')
         if len(lsplit) < 2:
            continue
         lineDirec = lsplit[0].strip()
         if lineDirec in lineNumDict:
            lineNumDict[lineDirec] = (ind, lsplit[1].strip())
         

      rootname = lineNumDict[rootNameText][1]
      datadir = lineNumDict[dataDirText][1]
      
      # Get true root name and fix or add line
      if numRootOpts:
         rootname = rootByOption[dfileInd]
         rootDirect = copyPrefix + 'name = ' + rootname
         rewriteBatch = True
         if lineNumDict[rootNameText][0] >= 0:
            directLines[lineNumDict[rootNameText][0]] = rootDirect
         else:
            directLines.append(rootDirect)

      # Take care of the data directory now
      if numCurrent and rootname:
         if not deliverDir:
            datadir = imodAbsPath(currentDirs[dfileInd])

         # If delivery, now we can make the directory
         # But we can't deliver file(s) until we know about dual/single
         else:
            datadir = imodAbsPath(os.path.join(deliverDir, rootname))
            if not (os.path.exists(datadir) and os.path.isdir(datadir)):
               if os.path.exists(datadir):
                  abortSet(datadir + ' already exists and is not a directory')
                  return 1
               try:
                  os.mkdir(datadir)
               except OSError:
                  abortSet('Error making directory for dataset, ' + datadir)
                  return 1

               prnLog('Created dataset directory ' + datadir)

         dataDirect = dataDirText + ' = ' + datadir
         rewriteBatch = True
         if lineNumDict[dataDirText][0] >= 0:
            directLines[lineNumDict[dataDirText][0]] = dataDirect
         else:
            directLines.append(dataDirect)

      # Now check and resolve pathless templates
      for (tmplText, ind) in ((scopeTmplText, 0), (sysTmplText, 1), (userTmplText, 2)):
         tmplName = lineNumDict[tmplText][1]
         if tmplName:
            (absTmplName, err) = absTemplatePath(tmplName, ind)
            if err == -1:
               abortSet('Directive for ' + direcFileErrorNames[ind] + ' name must be ' +\
                           'either an absolute path or just a filename, it is ' +tmplName)
               return 1
            if err < 0: 
               abortSet(direcFileErrorNames[ind] + ' file ' + tmplName + \
                           ' not found in expected location')
               return 1
            if err > 0:
               rewriteBatch = True
               directLines[lineNumDict[tmplText][0]] = tmplText + ' = ' +\
                              absTmplName

      # Deliver raw boundary model(s) and adjust directive to local file
      if deliverDir:
         for operation in (patchTrackText, autoSeedText):
            for axlet in ('.a.', '.b.', '.any.'):
               direc = operation + axlet + 'rawBoundaryModel'
               if lineNumDict[direc][0] >= 0:
                  srcPath = lineNumDict[direc][1]
                  rawFile = os.path.basename(srcPath)
                  destPath = os.path.join(datadir, rawFile)
                  srcExists = os.path.exists(srcPath)
                  destExists = os.path.exists(destPath)
                  if srcExists and not destExists:
                     try:
                        os.rename(srcPath, destPath)
                        prnLog('Moved boundary model ' + srcPath + ' to ' + datadir)
                     except OSError:
                        abortSet('Error renaming/moving raw boundary model ' + srcPath + \
                                    ' to ' + destPath)
                        return 1

                  elif not (destExists and not srcExists):
                     abortSet('Raw boundary model ' + srcPath + ' does not exist')
                     return 1

                  rewriteBatch = True
                  directLines[lineNumDict[direc][0]] = direc + ' = ' + rawFile
               
      # Rewrite the batch file with all these corrections in the data directory
      if rewriteBatch:
         absDirectiveFile = os.path.join(datadir, localBatchCopy)
         if writeTextFileReportErr(absDirectiveFile, directLines):
            return 1

   # Back to general processing of all kinds of files
   validErr = []
   for ind in range(len(directLines)):
      line = directLines[ind].lstrip()
      if line.startswith('#') or line == '':
         continue
      lsplit = line.split('=')
      if len(lsplit) < 2:
         validErr.append('Directive from ' + filename + ' lacks an = separator: ' + line)
         continue
      if lsplit[0].strip() == '':
         validErr.append('Directive from ' + filename + ' lacks a key: ' + line)
         continue
      allDirectives[index][lsplit[0].strip()] = (lsplit[1].strip(), ind)

   return printDirectiveErrors(validErr)
   

# Look for a directive with the given prefix and "option" (which might include a process)
# starting in the given directive dictionary, and converting by the type
def lookupDirective(prefix, option, startDct, valType):
   bestDict = -1
   if prefix.startswith(comPrefix):
      keys = [prefix + '.' + option, prefix + 'a.' + option, prefix + 'b.' + option]
   else:
      keys = [prefix + '.any.' + option, prefix + '.a.' + option, prefix + '.b.' + option]
   keyCheck = [(0, 1), (0, 1), (0, 2)]
   for dct in range(startDct, BatInd + 1):
      for keyInd in keyCheck[axisNum]:
         if keys[keyInd] in allDirectives[dct]:
            better = True
            newInd = allDirectives[dct][keys[keyInd]][1]

            # If two entries are equivalent with regard to axis preference, new one is
            # better if it comes from later dictionary or was later in file
            equivBetter = dct > bestDict or newInd > bestInd
            if bestDict >= 0:

               # For dual axis, new one is better if it matches the current axis and
               # previous one did not; or if they are for same axis and this one is later
               if dualAxis:
                  better = (keyInd == axisNum and bestKeyInd != axisNum) or \
                      (keyInd == bestKeyInd and equivBetter)
               else:

                  # For single axis, all "any" and "a" entries are equivalent
                  better = equivBetter

            if better:
               bestDict = dct
               bestInd = newInd
               bestKeyInd = keyInd

   # If nothing was found, return None, or 0 for a boolean
   if bestDict < 0:
      if valType == BOOL_VALUE:
         return 0
      return None

   # Otherwise return 1 for a boolean only if it is specifically 1, or return the
   # converted value, or the string
   value = allDirectives[bestDict][keys[bestKeyInd]][0]
   if valType == BOOL_VALUE:
      if value == '1':
         return 1
      return 0
   elif valType == INT_VALUE or valType == FLOAT_VALUE:
      if value == '':
         return None
      try:
         if valType == INT_VALUE:
            numval = int(value)
         else:
            numval = float(value)
         return numval
      except ValueError:
         return 'ERROR'
   else:
      return value


# Get all the directives for making a com file after the fact
def laterComDirectives(comfile, process, startInd):
   lines = []
   if startInd < 1 and scopeTmplText in allDirectives[BatInd]:
      lines.append('ChangeParametersFile ' + allDirectives[BatInd][scopeTmplText][0])
   if startInd < 2 and sysTmplText in allDirectives[BatInd]:
      lines.append('ChangeParametersFile ' + allDirectives[BatInd][sysTmplText][0])
   if startInd < 3 and userTmplText in allDirectives[BatInd]:
      lines.append('ChangeParametersFile ' + allDirectives[BatInd][userTmplText][0])
   lines.append('ChangeParametersFile ' + absDirectiveFile)
   return lines
   

# "Use" a file to replace one in sequence, with options to save previous one as _orig
# or to make a backup file out of it
def useFileAsReplacement(useFile, oldFile, saveOrig, makeBackup):
   (base, ext) = os.path.splitext(oldFile)
   origname = base + '_orig' + ext
   try:
      if saveOrig and not os.path.exists(origname):
            err = oldFile + ' to ' + origname
            os.rename(oldFile, origname)
      elif makeBackup:
         makeBackupFile(oldFile)
      else:
         cleanupFiles([oldFile])
      err = useFile + ' to ' + oldFile
      os.rename(useFile, oldFile)
   except OSError:
      abortSet('Error renaming ' + err + ' : ' + str(sys.exc_info()[1]))
      return 1


# Run imodtrans to get a boundary model onto (prealigned) stack
# In case there was any screwup in pixel size change of boundary model, make sure it
# fits the current stack before transforming
def transformRawBoundaryModel(modelIn, modelOut):
   try:
      (panx, pany, panz) = getmrcsize(dataName + '.preali')
      comstr = fmtstr('imodtrans -I "{}.st" -i "{}.preali" -2 "{}.prexg" -S {} -tx {}' +\
                         ' -ty {} "{}" "{}"', dataName, dataName, dataName,
                      1. / coarseBinning, (panx - rawXsize // coarseBinning) / 2.,
                      (pany - rawYsize // coarseBinning) / 2., modelIn, modelOut)
      prnLog('Transforming ' + modelIn + ' to ' + modelOut + ' with:\n' + comstr)
      runcmd(comstr)
   except ImodpyError:
      reportImodError('Could not transform boundary model to match stack')
   

# Check for a Q in the check file and just exit, unless some reason to return turns up
def checkForQuit():
   global finishSetAndQuit
   if not os.path.exists(checkFile):
      return False
   checklines = readTextFile(checkFile, None, True)
   if isinstance(checklines, str) or len(checklines) < 1:
      return False
   if checklines[-1].startswith('Q'):
      writeTextFile(proChunkCheckFile, ['Q'], True)
      prnLog('RECEIVED SIGNAL TO QUIT, JUST EXITING')
      sys.exit(0)
   if checklines[-1].startswith('F'):
      if not finishSetAndQuit:
         prnLog('RECEIVED SIGNAL TO FINISH CURRENT SET AND EXIT', flush = True)
      finishSetAndQuit = True


# Runs a com file or com chunks using processchunks
def runOneProcess(comfile, single = True, usingGPU = False, message = '',
                  useMostCPUs = False):
   if (single or 'sirt' not in comfile) and not os.path.exists(comfile):
      abortSet('Command file ' + comfile + ' does not exist')
      return 1
   sleepTime = 0.2
   startingTimeOut = 60.
   readErrorTimeout = 30.
   checkInterval = 5.
   
   # Check for quitting then compose the command array
   checkForQuit()
   comArray = ['processchunks', '-P', '-g', '-c', proChunkCheckFile, '-n', str(niceness)]
   outfile = 'processchunks' + axisLet + '.out'
   if remoteDataDir:
      comArray += ['-w', remoteDataDir]
   machines = cpuList
   (comroot, ext) = os.path.splitext(comfile)
   if message:
      mess = message + ' (running ' + comfile
   else:
      mess = 'Running ' + comfile

   if single:

      # Figure out the machine to use for single and its thread limit if possible
      threads = firstCpuLimit
      if useMostCPUs:
         machines = topCPUmachine
         threads = topCpuLimit
      elif not useFirstCPUforSingle:
         machines = '1'
         threads = localCpuLimit
      comArray += ['-s', '-e', '1']
      if threads > 0:
         comArray += ['-O', str(threads)]
      comuse = comfile
   else:
      mess += ' in multiple chunks'
      comuse = comroot
   if usingGPU:
      machines = gpuList
      if machines != '1':
         comArray.append('-G')
      mess += ' using GPU'
   if message:
      mess += ')'
   if not machines:
      machines = '1'
   comArray += [machines, comuse]

   # Run the process detached
   prnLog(mess, flush=True)
   startTime = time.time()
   err = bkgdProcess(comArray, outfile, 'stdout', True)
   if err:
      prnLog('ERROR: ' + err)
      abortSet('Cannot start processchunks to run ' + comfile)
      return 1

   # Monitor the log and wait for completion
   elapsed = 0.
   gotLinesAt = -1.
   opened = False
   readOK = False
   gotPID = False
   finished = 0
   checkTime = 0.
   where = None
   try:
      while True:
         try:

            # Keep track of whether it opened and whether it read lines without an error
            if not opened:
               out = open(outfile, 'r')
               opened = True
            else:
               where = out.tell()
               lines = out.readlines()
               readOK = True
               if lines:

                  # Keep track of last time lines were gotten without error and look for
                  # various terminations
                  gotLinesAt = elapsed
                  where = None
                  for l in lines:
                     if l.startswith('ERROR:'):
                        prnLog('processchunks ' + l, end = '')
                        finished = -1
                        break
                     elif l.startswith('Finished reassembling'):
                        finished = 1
                        break
                     elif 'retain' in l and 'existing' in l:
                        finished = -2
                        break
                     elif 'PID:' in l:
                        gotPID = True

         except IOError:
            readOK = False
            pass

         if finished:
            break
         # Check for various timeouts and quit
         if not opened and elapsed > startingTimeOut:
            abortSet('Timeout occurred before processchunks output file could be ' +\
                        'opened for monitoring')
            return 1
         if readOK and gotLinesAt < 0 and elapsed > startingTimeOut:
            abortSet('Timeout occurred before processchunks started')
            return 1

         if readOK and not gotPID and elapsed > startingTimeOut:
            abortSet('Processchunks apparently failed to run; check ' + \
                        os.path.join(datasetDir, outfile) + ' for messages')
            return 1

         # If can't get the output, tell processchunks to quit but keep going to next set
         if opened and not readOK and \
                elapsed - gotLinesAt > readErrorTimeout:
            writeTextFile(proChunkCheckFile, ['Q'], True)
            time.sleep(5.)
            abortSet('Unable to read processchunks output file without an error')
            return 1

         # Check for Q ourselves in case processchunks is lost
         if elapsed - checkTime > checkInterval:
            checkTime = elapsed
            checkForQuit()
         
         elapsed += sleepTime
         time.sleep(sleepTime)

         # Seek to the last location before trying again if nothing was gotten.  This is
         # a trick from stackoverflow.com and is needed on Mac
         try:
            if where != None:
               out.seek(where)
         except IOError:
            pass

   except KeyboardInterrupt:
      writeTextFile(proChunkCheckFile, ['Q'], True)
      prnLog('Detected keyboard interrupt, told processchunks to quit')
      sys.exit(1)

   if opened:
      try:
         out.close()
      except Exception:
         pass

   doPrint = True
   if finished == 1:
      for comskip in handlingMessages:
         if comskip in comroot:
            doPrint = False
            break
      
   # Get error and warnings from logs
   if single and doPrint:
      printTaggedMessages(comroot + '.log', standardTags)
   else:
      printTaggedMessages(outfile, [('WARNING:', 0)])
   
   # After loop, one last check for quit and some more set aborts
   checkForQuit()
   if finished == -1:
      abortSet('An error occurred running ' + comfile)
   elif finished == -2:
      abortSet('Strangely, processchunks quit but Q was not detected in the check file')
   elif finished == 1:
      (minutes, seconds, frac) = elapsedComponents(startTime);
      prnLog(fmtstr('Successfully finished {}   in {:02d}:{:02d}.{}\n', comfile, minutes,
                    seconds, frac), flush=True)
   return finished < 0


# Give lines for running makecomfile, add the output file entry, get  the com file, and
# run it
def makeAndRunOneCom(comlines, comfile, message = ''):
   comlines.insert(0, 'OutputFile	' + comfile)
   try:
      runcmd('makecomfile -StandardInput', comlines)
   except ImodpyError:
      reportImodError('Error making ' + comfile)
      return 1

   if runOneProcess(comfile, message = message):
      return 1
   return 0


# Use the sed commands to modify a command file, write it, and run it
# Reads the command file first unless lines are supplied in inLines
def modifyWriteAndRunCom(comfile, sedcom, inLines = None, message = ''):
   if not inLines:
      inLines = readTextFileReportErr(comfile)
      if not inLines:
         return 1
               
   if pysed(sedcom, inLines, comfile, retErr=True):
      abortSet('Error modifying ' + comfile)
      return 1
   if runOneProcess(comfile, message = message):
      return 1
   return 0
   

# Finds and converts a single value after a token like '=' on the given line
# Throws ValueError if token doesn't exist or value has conversion error
def getOneValueAfterToken(line, token, valType):
   ind = line.find(token) + 1
   if ind < 1:
      junk = int('=')
   if valType == INT_VALUE:
      return int(line[ind:])
   else:
      return float(line[ind:])


# Analyze tiltalign log file for angle, shift, and thickness
def analyzeAlignLog(twoSurf, angleArr):

   # Fraction of shift to subtract from fiducial-based thickness to get reconstruction
   # thickness, and minimum on each side before doing that
   thickShiftFrac = 1.
   minFidAdjustThick = 4
   angleArr[0:5] = 5 * [0.]
   
   try:
      loglines = runcmd('alignlog -a align' + axisLet + '.log')
   except ImodpyError:
      reportImodError('Extracting angle analysis from align log')
      return 1
   
   tags = ['Total tilt angle change', 'X axis tilt needed', 'Unbinned thickness',
           'Incremental unbinned shift', 'Total unbinned shift']
   numBot, numTop = -1, -1
   try:
      for line in loglines:
         if '# of points' in line:

            # There can be one or three of these entries, so the second one replaces
            # numBot and the third one gives numTop
            num = getOneValueAfterToken(line, '=', INT_VALUE)
            if numBot < 0:
               numBot = num
            elif numTop < 0:
               numBot = num
               numTop = 0
            else:
               numTop = num
         for ind in range(len(tags)):
            if tags[ind] in line:
               angleArr[ind] = getOneValueAfterToken(line, '=', FLOAT_VALUE)
   except ValueError:
      abortSet('Error extracting information from align log')
      return 1

   # For two surfaces, also compute a reconstruction thickness (thickness are floats here)
   if twoSurf:
      angleArr[5] = angleArr[2]
      if numBot >= minFidAdjustThick and numTop >= minFidAdjustThick:
         angleArr[5] -= thickShiftFrac * math.fabs(angleArr[4])
   angleArr[6] = numBot
   angleArr[7] = max(0, numTop)

   return 0


# Determine parameter modifications for a montage
# Inputs are the raw X and Y size of the montage and the desired aligned stack size
# Values put into frameArr are:
# 0,1: actual aligned stack X and Y size
# 2,3: starting X and Y coordinates for blend
# 4,5: ending X and Y coordinates for blend
# 6,7: actual blended raw/prealigned stack size = FULLIMAGE
# 8,9: SUBSETSTART X and Y
# This function can be moved to imodpy so etomo can access it from a script
def montageFrameValues(nxmont, nymont, nxali, nyali, frameArr):

   # aligned stacksize
   (frameArr[0], frameArr[1]) = runGoodframe(nxali, nyali)
   (frameArr[6], frameArr[7]) = runGoodframe(nxmont, nymont)
   if frameArr[0] < 0 or frameArr[6] < 0:
      return min(frameArr[0], frameArr[6])

   # starting coordinates X and Y for blend
   frameArr[2] = -((frameArr[0] - nxmont) // 2)
   frameArr[3] = -((frameArr[1] - nymont) // 2)
   
   # ending for blend, and SUBSETSTART
   for ind in (0, 1):
      frameArr[ind + 4] = frameArr[ind + 2] + frameArr[ind] - 1
      frameArr[ind + 8] = -((frameArr[ind] - frameArr[ind + 6]) // 2)

   return 0


# Common place to fetch the name of com file and process for newstack or blendmont
def comAndProcessForAlignedStack(prefix):
   if ifMontage:
      comRoot = prefix + 'blend'
      process = 'blendmont'
   else:
      comRoot = prefix + 'newst'
      process = 'newstack'
   return (comRoot, process)


# Run a tilt comfile, splitting it if appropriate
def splitAndRunTilt(comfile, message):
   numProc = 0
   if parallelGPU > 1:
      numProc = parallelGPU
   elif parallelCPU and not useGPU:
      numProc = parallelCPU
   if numProc:
      try:
         runcmd('splittilt -n ' + str(numProc) + ' ' + comfile)
      except ImodpyError:
         reportImodError('Error running splittilt on ' + comfile)
   return runOneProcess(comfile, numProc == 0, useGPU, message = message)


# Run findsection on a file, produce a tomopitch model or fill array with Z limits
def runFindSection(filename, numScales, boxSize, pitchMod = None, topBots = None,
                   block = None):
   limitKeys = ['Median Z values', 'autopatchfit combine', 'Absolute limits']
   comRoot = 'findsection_tmp.'
   comLines = ['$findsection -StandardInput',
               'TomogramFile ' + filename,
               'NumberOfDefaultScales ' + str(numScales),
               fmtstr('SizeOfBoxesInXYZ {0},1,{0}', boxSize)]
   if pitchMod:
      comLines.append('TomoPitchModel ' + pitchMod)
      comLines.append('NumberOfSamples 5')
      if block:
         comLines.append('BlockSize ' + str(block))
   if writeTextFileReportErr(comRoot + 'com', comLines):
      return 1
   mess = 'Finding Z limits of the material in the tomogram'
   if pitchMod:
      mess = 'Getting a model for tomogram positioning'
   if runOneProcess(comRoot + 'com', message = mess):
      return 1
   if topBots:
      loglines = readTextFileReportErr(comRoot + 'log')
      if not loglines:
         return 1
      for line in loglines:
         for ind in (0, 1, 2):
            if limitKeys[ind].lower() in line.lower():
               lsplit = line.split()
               try:
                  topBots[2 * ind] = int(lsplit[-2])
                  topBots[2 * ind + 1] = int(lsplit[-1])
               except Exception:
                  abortSet('Error converting Z limits in: ' + line)
                  return 1

   return 0


# Parse a log from tomopitch to get the thickness, angles, and Z shift
def parseTomopitchLog(angleArr):
   pitchFile = 'tomopitch' + axisLet + '.log'
   tags = ['x-tilted  lines', 'X axis tilt -', 'Angle offset -', 'Z shift -']

   if not lookupDirective(runtimePrefix + 'Positioning', 'sampleType', 0, INT_VALUE):
      return 1
   if not os.path.exists(pitchFile):
      return 1
   pitchLines = readTextFileReportErr(pitchFile)
   if not pitchLines:
      return -1

   for line in pitchLines:
      if 'ERROR: ' in line:
         return 2
      for ind in range(4):
         if tags[ind] in line:
            lsplit = line.split()
            try:
               if ind:
                  angleArr[ind] = float(lsplit[-1])
               else:
                  angleArr[ind] = int(lsplit[-1])
            except ValueError:
               abortSet('Error converting tomopitch output of ' + \
                           tags[ind].replace(' -', '') + ' to a number')
               return -1

   return 0


# Look up whether SIRT and both were done, and compose the name of the SIRT rec from
# the leave iterations directive.  Return a name of None if SIRT was not done or an
# integer 1 if it was but the name can't be made
def getSIRTrecName(recRoot):
   doSIRT = lookupDirective(runtimePrefix + 'Reconstruction', 'useSirt', 0, BOOL_VALUE)
   doBPalso = lookupDirective(runtimePrefix + 'Reconstruction', 'doBackprojAlso', 0,
                              BOOL_VALUE)
   doBoth = doSIRT and doBPalso
   recName = None
   if doSIRT:
      leaveList = lookupDirective(comPrefix + 'sirtsetup', 'sirtsetup.LeaveIterations', 0,
                                  STRING_VALUE)
      if leaveList:
         lsplit = leaveList.replace('-',',').split(',')
         lastOne = lsplit[-1:][0]
         if len(lastOne) < 2:
            lastOne = '0' + lastOne
         recName = recRoot + '.srec' + lastOne
      else:
         recName = 1

   return (doSIRT, doBoth, recName)


# Run clip stats on raw or fixed stack
def runClipStats(command, stackSuffix, descrip):
   comfile = dataName + stackSuffix + '.st.stats.com'
   if writeTextFileReportErr(comfile, [command]):
      return None
   err = runOneProcess(comfile, message = 'Getting statistics for ' + descrip + ' stack')
   cleanupFiles([comfile])
   if err:
      return None

   # Extract the summary lines
   clipLines = readTextFileReportErr(dataName + stackSuffix + '.st.stats.log')
   return clipLines


# Test whether a step should be run
def needStep(step):
   return step >= startingStep - 0.005 and step <= endingStep + 0.005


# Report a step was reached if it is in the range to run and in the list to report
def reportReachedStep(step):
   reachPoints = (6, 7, detect3DstepNum)
   if step in reachPoints and needStep(step):
      prnstr('Reached step ' + str(step))
      prnstr('', flush = True)


# SINGLE-CALL FUNCTIONS FOR INITIAL STEPS

# Read in a validation file as a csv and store the directives in dictionaries
def processValidationFile():
   comPref = comPrefix[:-1]
   runPref = runtimePrefix[:-1]
   try:
      message = 'Opening '
      csvfile = open(validateFile, 'r')
      message = 'Using csv reader on '
      reader = csv.reader(csvfile)
      validLines = []
      for row in reader:
         validLines.append(row)
   except Exception:
      exitError(message + validateFile)

   for line in validLines:
      if len(line) > 1 and len(line[1]) > 0:
         lsplit = line[0].split('.')
         if len(lsplit) < 2:
            continue
         batchOK = len(line) > 3 and line[3] == 'Y'
         templateOK = len(line) > 4 and line[4] == 'Y'
         isBool = len(line) > 2 and line[2].lower() == 'bool'
         if lsplit[0] == comPref:
            if len(lsplit) < 4:
               continue
            combase = lsplit[1]
            if combase not in baseComDict:
               baseComDict[combase] = combase
               baseComDict[combase + 'a'] = combase
               baseComDict[combase + 'b'] = combase
            key = lsplit[1] + '.' + lsplit[2] + '.' + lsplit[3]
            validComDict[key.lower()] = (key, templateOK, batchOK, isBool)

         elif lsplit[0] == runPref:
            if len(lsplit) < 4:
               continue
            key = lsplit[1] + '.' + lsplit[3]
            validRunDict[key.lower()] = (key, templateOK, batchOK, isBool)

         else:
            validOtherDict[line[0].lower()] = (line[0], templateOK, batchOK, isBool)

            
# Look for every directive in the lists of valid ones from master file
def checkAllDirectives(mainFile = 'directive'):
   errors = []
   source = direcFileErrorNames[0:3] + [mainFile]
   types = ['template', 'batch directive']
   comPref = comPrefix[:-1]
   runPref = runtimePrefix[:-1]
   for ind in range(BatInd + 1):
      dirType = ind // BatInd
      if mainFile == 'template':
         dirType = 0
      for direc in allDirectives[ind]:
         messfrom = 'irective from ' + source[ind] + ' file'
         dsplit = direc.split('.')
         badCase = False
         OKforFile = True
         emptyBool = False
         valNotBool = allDirectives[ind][direc][0] != '0' and \
             allDirectives[ind][direc][0] != '1'
         if len(dsplit) < 2 or ((dsplit[0] == comPref or dsplit[0] == runPref) \
                                   and len(dsplit) < 4):
            errors.append('D' + messfrom + ' too short: ' + direc)

         # comparam first, start by checking the com file is in list
         elif dsplit[0] == comPref:
            comlow = dsplit[1].lower()
            if comlow not in baseComDict:
               errors.append('D' + messfrom + ' does not include a known com file: '
                             + direc)
            else:

               # Check for a match other than incorrect case
               combase = baseComDict[comlow]
               key = dsplit[1] + '.' + dsplit[2] + '.' + dsplit[3]
               if key.lower() in validComDict:
                  badCase = key != validComDict[key.lower()][0]
                  OKforFile = validComDict[key.lower()][dirType + 1]
                  emptyBool = validComDict[key.lower()][3] and valNotBool

               else:

                  # Look for a process match next
                  proclow = dsplit[2].lower()
                  for vkey in validComDict:
                     vsplit = vkey.split('.')
                     if vsplit[0] == combase and vsplit[1].lower() == proclow:
                        badCase =  dsplit[1] not in baseComDict or vsplit[1] != dsplit[2]
                        
                        # If the process matches, now try to find and read autodoc
                        optFile = PipOpenInstalledAdoc(vsplit[1])
                        errmess = ''
                        if optFile:
                           adocLines = readTextFile(optFile, None, True)
                           if isinstance(adocLines, str):
                              errmess = 'error reading it'
                        else:
                           errmess = 'error opening it at standard location'

                        # If no autodoc, issue a warning because we just can't tell
                        if errmess:
                           prnstr('WARNING: Unknown d' + messfrom + ': ' + direc)
                           prnstr('  Could not check ' + vsplit[1] + '.adoc because of '+\
                                     errmess)
                        else:

                           # Otherwise look for a case-insensitive match and report a
                           # bad case if any, otherwise report error if no match
                           target = fmtstr(r'\[ *Field *= *{} *\]', dsplit[3])
                           optMatch = re.compile(target)
                           optLC = re.compile(target, re.IGNORECASE)
                           for line in adocLines:
                              if re.match(optLC, line):
                                 if not re.match(optMatch, line):
                                    badCase = True
                                 break
                           else:  # ELSE ON FOR
                              errors.append('Unknown d' + messfrom + ': ' + direc)
                           
                        break
                  else:   # ELSE ON FOR
                     errors.append('D' + messfrom + ' does not include a known process: '
                                   + direc)

         # runtime next, check for a/b/any; all else must match
         elif dsplit[0] == runPref:
            if dsplit[2] not in ['any', 'a', 'b']:
               errors.append('D' + messfrom + ' does not include a/b/any: ' + direc)
            else:
               key = dsplit[1] + '.' + dsplit[3]
               if key.lower() in validRunDict:
                  badCase = key != validRunDict[key.lower()][0]
                  OKforFile = validRunDict[key.lower()][dirType + 1]
                  emptyBool = validRunDict[key.lower()][3] and valNotBool
               else:
                  errors.append('Unknown d' + messfrom + ': ' + direc)

         # Any other directives must match entirely
         else:
            if direc.lower() in validOtherDict:
               badCase = direc != validOtherDict[direc.lower()][0]
               OKforFile = validOtherDict[direc.lower()][dirType + 1]
               emptyBool = validOtherDict[direc.lower()][3] and valNotBool
            else:
               errors.append('Unknown d' + messfrom + ': ' + direc)
            
         if badCase:
            errors.append('D' + messfrom + ' has incorrect case: ' + direc)
         if not OKforFile:
            errors.append('D' + messfrom + ' is not intended for use in a ' + \
                             types[dirType] + ' file: ' + direc)
         if emptyBool:
            errors.append('D' + messfrom + ' is a boolean and must be 0 or 1: ' + direc)

   return printDirectiveErrors(errors)


# Look through directives for templates and basic setup parameters
def scanSetupDirectives():
   global datasetDir, dualAxis, setName, scanHeader, ifMontage, defocus, pixelSize
   global fidSizeNm, fidSizePix
   source = direcFileErrorNames

   batDirec = allDirectives[BatInd]
   scanHeader = scanHeadText in batDirec and batDirec[scanHeadText][0] == '1'
   ifMontage = False
   dualAxis = False
   pixelSize, fidSizeNm, fidSizePix = 0., 0., 0.
   datasetDir, setName = '', ''
   defocus = -1000000.
   if scopeTmplText in batDirec and \
          readDirectiveOrTemplate(batDirec[scopeTmplText][0], 0):
      return 1
   if sysTmplText in batDirec and \
          readDirectiveOrTemplate(batDirec[sysTmplText][0], 1):
      return 1
   if userTmplText in batDirec and \
          readDirectiveOrTemplate(batDirec[userTmplText][0], 2):
      return 1
   if copyPrefix + 'name' in batDirec:
      setName = batDirec[copyPrefix + 'name'][0]
   if dataDirText in batDirec:
      datasetDir = batDirec[dataDirText][0]
   for indDir in range(BatInd + 1):
      direc = allDirectives[indDir]
      try:
         if copyPrefix + 'montage' in direc:
            ifMontage = direc[copyPrefix + 'montage'][0] != '0'
         if copyPrefix + 'dual' in direc:
            dualAxis = direc[copyPrefix + 'dual'][0] != '0'
         if copyPrefix + 'pixel' in direc:
            ftext = direc[copyPrefix + 'pixel'][0]
            pixelSize = float(ftext)
         if copyPrefix + 'gold' in direc:
            ftext = direc[copyPrefix + 'gold'][0]
            fidSizeNm = float(ftext)
         if copyPrefix + 'defocus' in direc:
            ftext = direc[copyPrefix + 'defocus'][0]
            defocus = float(ftext)

      except ValueError:
         abortSet('Error converting the string "' + ftext + '" to float in ' +
                  source[indDir] + ' file')
         return 1

   if (not pixelSize and not scanHeader) or not setName or not datasetDir:
      abortSet('Pixel size missing from directives, and header is not being scanned')
      return 1
   if (not pixelSize and not scanHeader) or not setName or not datasetDir:
      abortSet('Set name or dataset directory missing from directives')
      return 1
   if defocus < -999999 and lookupDirective(runtimePrefix + 'AlignedStack', 'correctCTF',
                                            0, BOOL_VALUE):
      abortSet('Defocus must be entered to correct CTF')
      return 1

   return 0


# Get some basic processing flags, prealign binning, and dataset set
def getAxisInitialParameters():
   global rawXsize, rawYsize, zsize, fiducialless, coarseBinning, patchTrack
   fiducialless = lookupDirective(runtimePrefix + 'Fiducials', 'fiducialless', 0,
                                  BOOL_VALUE)
   trackMethod = lookupDirective(runtimePrefix + 'Fiducials', 'trackingMethod', 0,
                                INT_VALUE)
   patchTrack = isinstance(trackMethod, int) and trackMethod == 1

   (comRoot, process) = comAndProcessForAlignedStack('pre')
   coarseBinning = lookupDirective(comPrefix + comRoot, process + '.BinByFactor', 0,
                                   INT_VALUE)
   if isinstance(coarseBinning, str):
      abortSet('Error converting binning value in directive to integer')
      return 1
   if not coarseBinning:
      coarseBinning = 1
   
   try:
      if ifMontage:
         (rawXsize, rawYsize, zsize) = getMontageSize(dataName + '.st ', dataName + '.pl')
      else:
         (rawXsize, rawYsize, zsize) = getmrcsize(dataName + '.st')
   except ImodpyError:
      reportImodError('Error getting size of ' + dataName + '.st')
      return 1

   return 0


# Run imodtrans on a model to make it match existing raw stack,
# Then replace original file.  A failure is not fatal unless it leaves no raw model file
def fixModelHeaderForImage(model, image):
   if not os.path.exists(image) or not os.path.exists(model):
      return 0
   tmpName = model + '.transtemp'
   try:
      runcmd(fmtstr('imodtrans -I "{}" "{}" "{}"', image, model, tmpName))
   except ImodpyError:
      prnLog('WARNING: Could not fix coordinate information in model ' + model)
      reportImodError(None)
      return 0
   makeBackupFile(model)
   try:
      os.rename(tmpName, model)
   except OSError:
      prnLog('Error renaming fixed model ' + tmpName + ' to ' + model)
      return 1
   prnLog('Modified model ' + model + ' to adjust for change in pixel size of raw stack')
   return 0
            

# If pixel size was changed for an FEI file, make sure all raw boundary and X-ray models
# are changed so that they can still load correctly on the raw stacks
def fixAllSuppliedModelHeaders():
   modSet = set()
   bModSet = set()
   axList = ['a', 'any']
   if dualAxis:
      image = setName + 'a.st'
      modSet.add(setName + 'a.erase')
      axList.append('b')
      bModSet.add(setName + 'b.erase')
   else:
      image = setName + '.st'
      modSet.add(setName + '.erase')

   for operation in ('SeedFinding', 'PatchTracking'):
      for axLet in axList:
         key = runtimePrefix + operation + '.' + axLet + '.rawBoundaryModel'
         if key in allDirectives[BatInd]:
            rawBound = allDirectives[BatInd][key][0]
            if axLet == 'b':
               bModSet.add(rawBound)
            else:
               modSet.add(rawBound)

   for ind in range(len(modSet)):
      rawBound = modSet.pop()
      if fixModelHeaderForImage(rawBound, image):
         return 1

   for ind in range(len(bModSet)):
      rawBound = bModSet.pop()
      if fixModelHeaderForImage(rawBound, setName + 'b.st'):
         return 1


# SINGLE-CALL FUNCTIONS FOR PROCESSING STEPS AND A FEW HELPERS FOR THEM

# Look at SDs of images and exclude views (mean not used because base unknown)
def analyzeSDsAdjustExcludes(clipLines):
   numAverage = 5
   maxExclude = 3
   crit = lookupDirective(runtimePrefix + 'Preprocessing', 'endExcludeCriterion', 0,
                          FLOAT_VALUE)
   if testDirectiveValue(crit, 'Preprocessing.endExcludeCriterion', 'float'):
      return 1
   if crit <= 0.:
      return 0

   prnLog('Analyzing image SDs to see if views should be excluded at ends of series')

   # If there are no incoming lines from fixed stack, run on raw stack
   if not clipLines:
      clipLines = runClipStats('$clip stat ' + dataName + '.st', '', 'raw')
      if not clipLines:
         return 1

   # Extract the sds as second to last number
   sds = []
   for line in clipLines:
      if 'mean' in line or '-----' in line:
         continue
      if 'all' in line:
         break;
      lsplit = line.split()
      try:
         sds.append(float(lsplit[-1]))
      except Exception:
         abortSet('Error converting standard deviation to float in clip stats output')
         return 1

   if len(sds) < numAverage + 2 + 2 * maxExclude:
      return 0

   # Find out if there should be dark region analysis too
   darkRatio = lookupDirective(runtimePrefix + 'Preprocessing', 'darkExcludeRatio',
                               0, FLOAT_VALUE)
   darkFraction = lookupDirective(runtimePrefix + 'Preprocessing', 'darkExcludeFraction',
                                  0, FLOAT_VALUE)
   if testDirectiveValue(darkRatio, 'Preprocessing.darkExcludeRatio', 'float') or \
          testDirectiveValue(darkFraction, 'Preprocessing.darkExcludeFraction', 'float'):
      return 1
   if darkRatio == None:
      darkRatio = dfltDarkExcludeRatio
   if not darkFraction:
      darkFraction = dfltDarkExcludeFraction

   # Run histogram analysis if ratio is positive
   if darkRatio > 0.:
      numHist = min(zsize, 4 * maxExclude)
      clipcom = fmtstr('$clip hist -2d -s -iz 0-{},{}-{} {}.st', numHist / 2 - 1,
                       zsize - numHist / 2, zsize - 1, dataName)
      comfile = 'cliphist' + axisLet + '.com'
      if writeTextFileReportErr(comfile, [clipcom]):
         return 1
      if runOneProcess(comfile, message = 'Analyzing histograms for large dark areas'):
         return 1
      cleanupFiles([comfile])
      histLines = readTextFileReportErr('cliphist' + axisLet + '.log')
      if not histLines:
         return 1

      # Find which ones pass the criteria and add to list
      darkExcludes = []
      for line in histLines:
         if line.startswith('Slice ') and 'no histogram dip' not in line:
            
            lsplit = line.split()
            try:
               zval = int(lsplit[1].replace(':', ''))
               lowPeak = float(lsplit[4])
               highPeak = float(lsplit[6])
               fraction = float(lsplit[-1])
            except Exception:
               abortSet('Error converting output from clip hist')
               return 1
            if lowPeak < darkRatio * highPeak and fraction > darkFraction:
               darkExcludes.append(zval)

   # Look for low images at ends of series
   excludes = []
   baseInd = 0
   baseView = 1
   for direc in (1, -1):

      # use varying indentations before computing the mean; get the mean
      for indent in range(2, maxExclude + 2):
         goodMean = 0.
         for ind in range(numAverage):
            goodMean += sds[baseInd + direc * (ind + indent)] / numAverage

         # See how many consecutive views are below the criterion; stop at first above
         numLow = 0
         for ind in range(indent):
            if sds[baseInd + direc * ind] < crit * goodMean:
               numLow += 1
            else:
               break

         # Done if found any and there is one not below criterion (to be conservative)
         if numLow and numLow < indent:
            for ind in range(numLow):
               excludes.append(baseView + direc * ind)
            break

      # If looking for dark regions too, now look from the first non-excluded one for
      # consecutive ones that would be excluded on that basis
      if darkRatio > 0.:
         for ind in range(numLow, 2 * maxExclude):
            view = baseView + direc * ind
            if view - 1 in darkExcludes:
               excludes.append(view)
            else:
               break

      # Set up to repeat on ending views
      baseInd = -1
      baseView = len(sds)

   if not len(excludes):
      prnLog('No views have low SDs or dark regions near end of series')
      return 0
   
   # Get existing skip list
   skipLet = ''
   if axisLet == 'b':
      skipLet = 'b'
   directive = copyPrefix + skipLet + 'skip'
   excludes.sort()
   if directive in allDirectives[BatInd]:
      userExcludes = allDirectives[BatInd][directive][0]
      message = 'Added these views to existing list of views to skip: '
      numAdd = 0
      userList = parselist(userExcludes)
      for view in excludes:
         if view not in userList:
            userExcludes += ',' + str(view)
            message += ' ' + str(view)
            numAdd += 1
      if not numAdd:
         prnLog('Views with low SDs were already in the list of views to skip')
         return 0

   else:
      userExcludes = ''
      message = 'These views have low SDs or dark regions and will be skipped: '
      comma = ''
      for view in excludes:
         userExcludes += comma + str(view)
         comma = ','
         message += ' ' + str(view)

   prnLog(message)

   # Modify all four com files
   for (comRoot, option, afterOpt) in [('xcorr', 'SkipViews', 'RotationAngle'),
                                       ('track', 'SkipViews', 'RotationAngle'),
                                       ('align', 'ExcludeList', 'RotationAngle'),
                                       ('tilt', 'EXCLUDELIST2', 'XTILTFILE')]:
      comfile = comRoot + axisCom
      sedcom = sedDelAndAdd(option, userExcludes, afterOpt)
      inLines = readTextFileReportErr(comfile)
      if not inLines:
         return 1
      if pysed(sedcom, inLines, comfile, retErr=True):
         abortSet('Error modifying ' + comfile)
         return 1
      
   return 0


# Operations needed when using fiducialless alignment for final alignment
def fidlessFileOperations(taLines):
   global didLocalAlign, madeZfactors
   didLocalAlign = False
   madeZfactors = False
   rotarr = optionValue(taLines, 'RotationAngle', FLOAT_VALUE)
   if not rotarr:
      abortSet('Cannot find RotationAngle in align' + axisCom)
      return 1
   axisRot = rotarr[0]
   
   rotfile = 'rotation' + axisLet + '.xf'
   sinrot = math.sin(math.radians(axisRot))
   if writeTextFileReportErr(rotfile, [fmtstr('{0:.6f} {1:.6f} {2:.6f} {0:.6f} 0. 0.',
                                              math.cos(math.radians(axisRot)), sinrot,
                                              -sinrot)]):
      return 1

   try:
      runcmd('xftoxg -nfit 0 ' + dataName + '.prexf')
      runcmd(fmtstr('xfproduct {0}.prexg {1} {0}_nonfid.xf', dataName, rotfile))
      shutil.copyfile(dataName + '_nonfid.xf', dataName + '.xf')
      shutil.copyfile(dataName + '.rawtlt', dataName + '.tlt')
   except ImodpyError:
      reportImodError('Cannot prepare transformations')
      return 1
   except Exception:
      abortSet('Error copying xf or tlt file')
      return 1
   return 0


# Run tiltxcorr to do patch tracking
def runPatchTracking():
   contourPieces = lookupDirective(patchTrackText, 'contourPieces', 0, INT_VALUE)
   if isinstance(contourPieces, str):
      abortSet('Error converting contour pieces in directive to integer')
      return 1

   if not lookupDirective(comPrefix + 'xcorr_pt',
                          'tiltxcorr.SizeOfPatchesXandY', 0, STRING_VALUE):
      abortSet('Size of patches must be specified to use patch tracking')
      return 1

   # Start command list for running makecomfile
   comlines = ['InputFile xcorr' + axisCom,
               'BinningOfImages ' + str(coarseBinning),
               'RootNameOfDataFiles ' + dataName]
   comlines += laterComDirectives('xcorr_pt', 'tiltxcorr', 0)

   # Look for boundary models to transform
   rawBound = ''
   if not axisInd:
      rawBound = lookupDirective(patchTrackText, 'rawBoundaryModel', 0, STRING_VALUE)
   else:

      # A raw model for B has to be specific to the B axis
      key = runtimePrefix + 'PatchTracking.b.rawBoundaryModel'
      if key in allDirectives[BatInd]:
         rawBound = allDirectives[BatInd][key][0]
   
   # transform and add to com
   if rawBound:
      boundaryMod = dataName + '_ptbound.mod'
      if transformRawBoundaryModel(rawBound, boundaryMod): 
         return 1

      comlines.append(fmtstr('OneParameterChange {}xcorr_pt{}.tiltxcorr.' +
                             'BoundaryModel={}', comPrefix, axisLet, boundaryMod))

   # Convert runtime directive for contour pieces into com directive for imodchopconts
   if contourPieces and contourPieces > 1:
      if lookupDirective(comPrefix + 'xcorr_pt', 'imodchopconts.LengthOfPieces', 0,
                         STRING_VALUE):
         abortSet('Both xcorr_pt.imodchopconts.LengthOfPieces and ' +\
                     'PatchTracking.contourPieces were entered; only one is allowed')
         return 1
      comlines.append(fmtstr('OneParameterChange {}xcorr_pt{}.imodchopconts.' + \
                                'NumberOfPieces={}', comPrefix, axisLet, contourPieces))

   if makeAndRunOneCom(comlines, 'xcorr_pt' + axisCom,
                       'Tracking patches to make alignment model'):
      return 1


# Get fiducial model by seeding and tracking or by RAPTOR
def makeSeedAndTrack(talines):
   global lightBeads, haveAaxisAFSbound
   trackingMethod = lookupDirective(runtimePrefix + 'Fiducials', 'trackingMethod',
                                    0, INT_VALUE)
   numBTRuns = lookupDirective(runtimePrefix + 'BeadTracking', 'numberOfRuns',
                               0, INT_VALUE)
   seedingMethod = lookupDirective(runtimePrefix + 'Fiducials', 'seedingMethod',
                                   0, INT_VALUE)
   
   if isinstance(trackingMethod, str) or isinstance(numBTRuns, str) or \
          isinstance(seedingMethod, str):
      abortSet('Error converting tracking method or number of runs to integer')
      return 1
   if not trackingMethod:
      trackingMethod = 0
   if trackingMethod < 0 or trackingMethod > 2:
      abortSet('trackingMethod must be between 0 and 2')
   if (seedingMethod == None or seedingMethod < 1 or seedingMethod > 3 or \
          (axisInd == 0 and seedingMethod == 2)) and trackingMethod == 0:
      abortSet('seedingMethod must be between 1 and 3 and not be 2 for first/only axis')
      return 1

   # If runs is not there, assume 0 for RAPTOR and 1 for other
   if numBTRuns == None:
      if trackingMethod == 2:
         numBTRuns = 0
      else:
         numBTRuns = 1
   if numBTRuns <= 0 and trackingMethod != 2:
       abortSet('Number of beadtrack runs must be > 0 unless using RAPTOR')
       return 1

   # Modify track.com with ImageBinned entry
   btlines = readTextFileReportErr('track' + axisCom)
   if not btlines:
      return 1
   sedcom = sedDelAndAdd('ImagesAreBinned', coarseBinning, 'OutputModel')
   if pysed(sedcom, btlines, 'track' + axisCom, retErr=True):
      abortSet('Error modifying track' + axisCom)
      return 1
   lightBeads = optionValue(btlines, 'LightBeads', BOOL_VALUE)

   # RAPTOR
   if needStep(4) and trackingMethod == 2:
      markers = lookupDirective(runtimePrefix + 'RAPTOR', 'numberOfMarkers', 0,
                                INT_VALUE)
      if markers == None or isinstance(markers, str) or markers <= 0:
         abortSet('numberOfMarkers for RAPTOR missing, not positive, or gave ' +\
                     'conversion error')
         return 1

      if lookupDirective(runtimePrefix + 'RAPTOR', 'useAlignedStack', 0,
                         BOOL_VALUE):
         ext = 'preali'
         beadint = int(round(fidSizePix / coarseBinning))
      else:
         ext = 'st'
         beadint = int(round(fidSizePix))

      line = fmtstr('$runraptor -mark {} -diam {} {}.{}', markers, beadint, dataName, ext)
      if writeTextFileReportErr('runraptor' + axisCom,
                          ['# Command file to run raptor', line]):
         return 1
      if runOneProcess('runraptor' + axisCom, 'Tracking fiducials with RAPTOR'):
         return 1
      if useFileAsReplacement(dataName + '_raptor.fid', dataName + '.fid', False, True):
         return 1

   # Seed and track:
   elif needStep(4):

      # Transferfid for axis b
      skipAuto = False
      if axisInd > 0 and (seedingMethod & 2) != 0:
         comlines = ['RootNameOfDataFiles	' + setName]
         comlines += laterComDirectives('transferfid', 'transferfid', 0)
         comlines.append(fmtstr('OneParameterChange {}transferfid.transferfid.' +\
                                   'LowestTiltTransformFile={}_AtoB.xf', comPrefix,
                                setName))
         if makeAndRunOneCom(comlines, 'transferfid.com',
                             'Transferring fiducials from A to B axis'):
            return 1
         printTaggedMessages('transferfid.log',
                             standardTags + [('fiducials that failed', 4)])
         numFailed = findTaggedValue(latestMessages, 'fiducials that failed', ':',
                                     INT_VALUE)
         if numFailed != None and numFailed == 0:
            skipAuto = True

      # Autoseed
      if (seedingMethod & 1) != 0 and not skipAuto:
         twoSurf = 0
         if numSurfaces > 1:
            twoSurf = 1

         # If there is not a specific directive for two surfaces, set it based on
         # tiltalign entry
         comlines = laterComDirectives('autofidseed', 'autofidseed', 0)
         if axisInd > 0 and (seedingMethod & 2) != 0:
            comlines.append(fmtstr('OneParameterChange {}autofidseedb.autofidseed.' +
                                   'AppendToSeedModel=1', comPrefix))
         if lookupDirective(comPrefix + 'autofidseed', 'autofidseed.TwoSurfaces', 0,
                            STRING_VALUE) == None:
            comlines.append(fmtstr('OneParameterChange {}autofidseed{}.autofidseed.' +
                                   'TwoSurfaces={}', comPrefix, axisLet, twoSurf))

         # Boundary model has to be transformed if indicated
         # A model on A raw stack has to be transformed to preali
         boundaryMod = ''
         if not axisInd:
            rawBound = lookupDirective(autoSeedText, 'rawBoundaryModel',
                                       0, STRING_VALUE)
            haveAaxisAFSbound = rawBound != None and rawBound != ''
         else:

            # A raw model for B has to be specific to the B axis
            rawBound = ''
            key = runtimePrefix + 'SeedFinding.b.rawBoundaryModel'
            if key in allDirectives[BatInd]:
               rawBound = allDirectives[BatInd][key][0]

            # But if there is not a raw model for B, see if there was one for A
            # that can be transferred with the transform
            if not rawBound and haveAaxisAFSbound and (seedingMethod & 2) != 0:
               boundaryMod = dataName + '_afsbound.mod'
               try:
                  (panx, pany, panz) = getmrcsize(dataName + '.preali')
                  comstr = fmtstr('imodtrans -2 "{}_AtoB.xf" -l 0 -n {},{},{} ' +
                                '"{}a_afsbound.mod" "{}"', setName, panx, pany, panz,
                                  setName, boundaryMod)
                  runcmd(comstr)
               except ImodpyError:
                  reportImodError('Failed to transform boundary model from A to B')
                  return 1

         # Transform a raw model
         if rawBound:
            boundaryMod = dataName + '_afsbound.mod'
            if transformRawBoundaryModel(rawBound, boundaryMod): 
               return 1

         # Add boundary model to com
         if boundaryMod:
            comlines.append(fmtstr('OneParameterChange {}autofidseed{}.autofidseed.' +
                                   'BoundaryModel={}', comPrefix, axisLet, boundaryMod))
            
         if makeAndRunOneCom(comlines, 'autofidseed' + axisCom,
                             'Finding seed points for fiducial model'):
            return 1
         printTaggedMessages('autofidseed' + axisLet + '.log', standardTags +
                             [('candidate points, including', 4), ('Final:   total', 0)])

         # See if the bead size changed significantly and switch to it
         if lookupDirective(comPrefix + 'autofidseed', 'autofidseed.AdjustSizes', 0,
                            BOOL_VALUE):
            afsLines = readTextFileReportErr('autofidseed' + axisLet + '.log')
            if not afsLines:
               return 1
            newBeadSize = None
            for line in afsLines:
               if line.startswith('Adjusted parameters'):
                  try:
                     newBeadSize = float(line.split()[-1]) * coarseBinning
                  except ValueError:
                     abortSet('Converting new bead size found by imodfindbeads to float')
                     return 1
            if newBeadSize:
               diff = math.fabs(newBeadSize - fidSizePix) / fidSizePix

               # Significantly means a 5% change.  Watch out, track.com was already
               # modified so apply earlier change to lines instead of rereading it
               if diff < 0.95 or diff > 1.05:
                  prnLog('Changing the unbinned bead diameter for tracking to ' +
                         str(newBeadSize))
                  sedcom = [sedModify('BeadDiameter', newBeadSize)] + \
                      sedDelAndAdd('ImagesAreBinned', coarseBinning, 'OutputModel')
                  if pysed(sedcom, btlines, 'track' + axisCom, retErr=True):
                     abortSet('Error modifying track' + axisCom)
                     return 1
      

   # Run bead tracking indicated number of times
   if not needStep(5):
      numBTRuns = 0
   for trackInd in range(max(0, numBTRuns)):

      # After first time, save seed as _orig or back it up
      if (trackInd or trackingMethod == 2) and \
             useFileAsReplacement(dataName + '.fid', dataName + '.seed', True, True):
         return 1
      if runOneProcess('track' + axisCom, message =
                       'Tracking beads with Beadtrack, run # ' + str(trackInd + 1)):
         return 1
      printTaggedMessages('track' + axisLet + '.log',
                          standardTags + [('Total points missing =', 4)])
      missing = findTaggedValue(latestMessages, 'Total points missing', '=', INT_VALUE)
      if missing != None and missing == 0:
         break


# Set up tiltalign command file from taLine with the changes in sedcom, then run
# restrictalign unless skipping it and report results, then run tiltalign
#
def modifyRestrictAndRunAlign(comfile, sedcom, taLines, message, skipRestrict):
   global suppressAbort
   
   if pysed(sedcom, taLines, comfile, retErr=True):
      abortSet('Error modifying ' + comfile)
      return (-1, 0)

   retval = 0
   noRobust = 0
   if not skipRestrict:

      # Get directives to modify defaults if any when running restrictalign
      minRatio = lookupDirective(runtimePrefix + 'RestrictAlign', 'minMeasurementRatio',
                                 0, FLOAT_VALUE)
      targetRatio = lookupDirective(runtimePrefix + 'RestrictAlign',
                                    'targetMeasurementRatio', 0, FLOAT_VALUE)
      resOrder = lookupDirective(runtimePrefix + 'RestrictAlign', 'orderOfRestrictions',
                                 0, STRING_VALUE)
      skipBT = lookupDirective(runtimePrefix + 'RestrictAlign', 'skipBeamTiltWithOneRot',
                               0, FLOAT_VALUE)

      # Set up the input and run it
      resInput = ['AlignCommandFile ' + comfile]
      if minRatio:
         resInput.append('MinMeasurementRatio ' + str(minRatio))
      if targetRatio:
         resInput.append('TargetMeasurementRatio ' + str(targetRatio))
      if resOrder:
         resInput.append('OrderOfRestrictions ' + resOrder)
      if skipBT:
         resInput.append('SkipBeamTiltWithOneRot 1')

      prnLog('Running restrictalign to check if alignment parameters need to be ' +\
                'restricted')
      try:
         resLines = runcmd('restrictalign -StandardInput', resInput)
      except ImodpyError:
         suppressAbort = False
         reportImodError('Error running restrictalign to set parameters if there are ' +\
                            'few fiducials')
         return (-1, 0)
      if not resLines:
         suppressAbort = False
         abortSet('No output received from restrictalign')
         return (-1, 0)

      # Echo all the output
      for line in resLines:
         prnLog(line.strip('\r\n'))
         if 'No restriction' not in line:
            retval = 1
         if 'off robust' in line:
            noRobust = 1
      prnLog(' ')
      if noRobust:
         message = message.replace('with robust', 'without robust')
         
   if runOneProcess(comfile, message = message):
      return (-2, noRobust)
   return (retval, noRobust)


# Run tiltalign in 2 or 3 stages
def runTiltalign(taLines):
   global xtiltNeeded, fidThickness, fidIncShift, reconThickness, didLocalAlign
   global madeZfactors, totalDelTilt, suppressAbort, finalAlignResid

   minTotGlblStretch = 12
   minSurfGlblStretch = 4
   minRatioGlblStretch = 0.125
   minSurfLocalStretch = 1.0
   minTotSkipRestrict = 20
   minTotToSetAngle = 4
   
   # The command file should be configured by various inputs, so let's find out some
   didLocalAlign = optionValue(taLines, 'LocalAlignments', BOOL_VALUE)
   patchSizeArr = optionValue(taLines, 'TargetPatchSizeXandY', INT_VALUE, numVal = 2)
   minFidsArr = optionValue(taLines, 'MinFidsTotalAndEachSurface', INT_VALUE, numVal = 2)
   if not patchSizeArr or not minFidsArr:
      abortSet('Problem finding some options in align.com')
   (nxpatch, nypatch) = patchSizeArr
   (minFidsTot, minFidsSurf) = minFidsArr
   alignCom = 'align' + axisCom
   alignLog = 'align' + axisLet + '.log'
   doRobust = lookupDirective(comPrefix + 'align', 'tiltalign.RobustFitting', 0,
                              BOOL_VALUE)

   enableStretch = lookupDirective(runtimePrefix + 'TiltAlignment', 'enableStretching',
                                   0, BOOL_VALUE)
   if patchTrack:
      enableStretch = False

   # If skipping align, get a few more values from com file, analyze log
   if skipTiltalign:
      glbStretch = optionValue(taLines, 'XStretchOption', INT_VALUE, numVal = 1)
      madeZfactors = glbStretch != None and glbStretch > 0
      angleArr = [0., 0., 0., 0., 0., 0., 0, 0]
      if analyzeAlignLog(numSurfaces > 1, angleArr):
         return 1
      (totalDelTilt, xtiltNeeded, fidThickness, fidIncShift, fidTotalShift, \
          reconThickness, numBot, numTop) = angleArr
      return 0
   
   # first time, turn off local align and make sure stretch/skew off
   # But loop twice in case have to turn off robust fitting
   for loop in (0, 1):
      robText = 'without'
      if doRobust:
         robText = 'with'
      mess = 'Doing fine alignment with no distortion or local alignments, ' + \
          robText + ' robust fitting'
      suppressAbort = not loop and doRobust
      sedcom = [sedModify('SurfacesToAnalyze', numSurfaces),
                sedModify('LocalAlignments', 0),
                sedModify('XStretchOption', 0),
                sedModify('SkewOption', 0)] + \
                sedDelAndAdd('ImagesAreBinned', coarseBinning, 'OutputTransformFile') + \
                sedDelAndAdd('ScaleShifts', '1,' + str(coarseBinning), 'InputFile2')+ \
                sedDelAndAdd('RobustFitting', doRobust, 'OutputTransformFile')

      (restricted, noRobust) =  modifyRestrictAndRunAlign(alignCom, sedcom, taLines, mess,
                                                          False)
      if noRobust:
         doRobust = 0
      if restricted < 0:
         if not suppressAbort:
            return 1
         suppressAbort = False
         for line in latestMessages:
            if 'TOO FEW DATA POINTS TO DO ROBUST' in line:
               prnLog('Trying again without robust fitting')
               doRobust = 0
               break
         else:    # ELSE ON FOR
            return 1

         continue

      messageTags = standardTags + [('Residual error', 4)]
      printTaggedMessages(alignLog, messageTags)
      break

   suppressAbort = False
   angleArr = [0., 0., 0., 0., 0., 0., 0, 0]
   if analyzeAlignLog(numSurfaces > 1, angleArr):
      return 1
   (totalDelTilt, xtiltNeeded, fidThickness, fidIncShift, fidTotalShift, \
       reconThickness, numBot, numTop) = angleArr
   if numSurfaces > 1:
      totalFid = numBot + numTop
      minOnSurf = min(numBot, numTop)
   else:
      totalFid = numBot

   localAlign = 0
   glbStretch = 0
   locStretch = 0
   useMinFids = 0
   numruns = 1
   madeZfactors = False
   if didLocalAlign and not restricted:
      localAlign = 1
      messageTags = standardTags + [('(Global)', 4), ('error local mean:', 4)]
   else:
      didLocalAlign = 0
   if not restricted and (didLocalAlign or enableStretch):
      if didLocalAlign:
         numruns = 2

      # are there enough fids for stretch?
      if enableStretch:
         if totalFid > minTotGlblStretch and \
                (numSurfaces == 1 or \
                    (minOnSurf > minSurfGlblStretch and \
                        min(numBot, numTop) / float(totalFid) > minRatioGlblStretch)):
            glbStretch = 3
            madeZfactors = True
            numruns = 2
            if didLocalAlign and numSurfaces > 1:
               mindens = minOnSurf / float(rawXsize * rawYsize)
               minInArea = mindens * nxpatch * nypatch
               if minInArea > minSurfLocalStretch:
                  locStretch = 3
                  useMinFids = minFidsSurf
               else:
                  prnLog('Too few fiducials on minority surface to enable local ' +\
                            'stretching solution')

         else:
            prnLog('Too few fiducials on minority surface to enable ' +\
                            'stretching solution')
            
   
   # Just run alignment once or twice more.  Again, if robust gives a problem, try it
   # without; and this time if local alignments failed, drop that out too
   for run in range(numruns):
      for loop in (0, 2):
         robText = 'without'
         if doRobust:
            robText = 'with'
         mess = 'Doing fine alignment with '
         if not glbStretch:
            mess += 'no'
         mess += ' distortion, with'
         if restricted or not didLocalAlign:
            mess += 'out'
         mess += ' local alignments, ' + robText + ' robust fitting'
         suppressAbort = not loop and doRobust
         delTilt = totalDelTilt
         if totalFid < minTotToSetAngle:
            delTilt = 0.
         sedcom = [sedModify('SurfacesToAnalyze', numSurfaces),
                   sedModify('LocalAlignments', localAlign),
                   sedModify('XStretchOption', glbStretch),
                   sedModify('SkewOption', glbStretch),
                   sedModify('LocalStretchOption', locStretch),
                   sedModify('LocalSkewOption', locStretch),
                   sedModify('MinFidsTotalAndEachSurface', fmtstr('{},{}', minFidsTot,
                                                                  useMinFids)),
                   sedModify('AngleOffset', delTilt)] + \
                   sedDelAndAdd('ImagesAreBinned', coarseBinning, 'OutputTransformFile')+\
                   sedDelAndAdd('ScaleShifts', '1,' + str(coarseBinning), 'InputFile2')+ \
                   sedDelAndAdd('RobustFitting', doRobust, 'OutputTransformFile')

         if madeZfactors:
            sedcom += sedDelAndAdd('OutputZFactorFile', dataName + '.zfac',
                                   'OutputTransformFile')
                
         (restricted, noRobust) =  modifyRestrictAndRunAlign \
             (alignCom, sedcom, taLines, mess, totalFid >= minTotSkipRestrict)
         if restricted < 0:
            if not suppressAbort:
               return 1
            suppressAbort = False
            for line in latestMessages:
               if 'TOO FEW DATA POINTS TO DO ROBUST' in line:
                  prnLog('Trying again without robust fitting')
                  doRobust = 0
                  break
               if 'Minimum numbers of fiducials are too high' in line:
                  prnLog('Trying again without local alignments')
                  didLocalAlign = 0
                  localAlign = 0
                  break
            else:     # ELSE ON FOR
               return 1

            continue
            
         printTaggedMessages(alignLog, messageTags)
         break

      suppressAbort = False
      if analyzeAlignLog(numSurfaces > 1, angleArr):
         return 1
      (totalDelTilt, xtiltNeeded, fidThickness, fidIncShift, fidTotalShift, \
          reconThickness, numBot, numTop) = angleArr

   # Find the last residual output message and echo it as the final result, save for eval
   for ind in range(len(latestMessages) - 1, -1, -1):
      line = latestMessages[ind]
      colonInd = line.find(':')
      if colonInd > 0 and 'error' in line and 'mean' in line:
         prnLog('Final align - ' + line.strip())
         prnLog('')
         lsplit = line[colonInd + 1:].split()
         finalAlignResid = 0.
         try:
            finalAlignResid = float(lsplit[0])
         except Exception:
            pass
         break
         
   return 0
     

# Make the aligned stack
def makeAlignedStack(positionBinning):
   global aliBinning, aliXunbinned, aliYunbinned
   alipre = runtimePrefix + 'AlignedStack'
   if positionBinning:
      aliBinning = positionBinning
      outsizeText = ''
      mess = 'Making binned aligned stack for whole tomogram positioning'

   else:
      aliBinning = lookupDirective(alipre, 'binByFactor', 0, INT_VALUE)
      if testDirectiveValue(aliBinning, 'AlignedStack.binByFactor', 'integer'):
         return 1
      outsizeText = lookupDirective(alipre, 'sizeInXandY', 0, STRING_VALUE)
      mess = 'Making final aligned stack'
      
   linear = lookupDirective(alipre, 'linearInterpolation', 0, BOOL_VALUE)
   aliXunbinned = rawXsize
   aliYunbinned = rawYsize
   if not aliBinning:
      aliBinning = 1
   if outsizeText:
      splits = outsizeText.replace(',', ' ').split()
      try:
         aliXunbinned = int(splits[0])
         aliYunbinned = int(splits[1])
      except:
         abortSet('Error converting aligned stack output size')
         return 1

   (comRoot, process) = comAndProcessForAlignedStack('')
   if ifMontage:
      err = montageFrameValues(rawXsize, rawYsize, aliXunbinned, aliYunbinned,
                               montFrameData)
      if err == 1:
         reportImodError("Error running goodframe on montage sizes")
         return 1
      if err:
         abortSet("Error converting output of goodframe to integers")
         return 1
      sedcom = [sedModify('StartingAndEndingX', fmtstr('{},{}', montFrameData[2],
                                                       montFrameData[4])),
                sedModify('StartingAndEndingY', fmtstr('{},{}', montFrameData[3],
                                                       montFrameData[5])),
                '/^InterpolationOrder/d']
      if linear:
         sedcom.append('/^TransformFile/a/InterpolationOrder    1/')
                
      aliXunbinned = montFrameData[0]
      aliYunbinned = montFrameData[1]

   else:
      sedcom =  [sedModify('SizeToOutputInXandY',
                           fmtstr('{},{}', aliXunbinned // aliBinning,
                                  aliYunbinned // aliBinning))] + \
                       sedDelAndAdd('LinearInterpolation', linear, 'TransformFile')
      

   sedcom += sedDelAndAdd('BinByFactor', aliBinning, 'TransformFile')
   if (positionBinning or needStep(8)) and \
          modifyWriteAndRunCom(comRoot + axisCom, sedcom, message = mess):
      return 1

   return 0
   

# Do optional CTF correction on aligned stack
def CTFPlotAlignedStack():
   global correctCTF

   # Do autofitting with ctfplotter if enabled
   correctCTF = lookupDirective(runtimePrefix + 'AlignedStack', 'correctCTF', 0,
                                BOOL_VALUE)
   autofit = lookupDirective(runtimePrefix + 'CTFplotting', 'autoFitRangeAndStep', 0,
                             STRING_VALUE)
   if needStep(ctfPlotStepNum) and correctCTF and autofit:
         ctfLines = readTextFileReportErr('ctfplotter' + axisCom)
         if not ctfLines:
            return 1
         sedcom = ['/^ExpectedDefocus/a/SaveAndExit	1/',
                   '/^ExpectedDefocus/a/AutoFitRangeAndStep	' + autofit + '/',
                   '/^AngleRange/d']

         # Make existing defocus file a backup to avoid error messages
         makeBackupFile(dataName + '.defocus')
         if modifyWriteAndRunCom('ctfplotter_auto' + axisCom, sedcom, ctfLines,
                                 'Finding defocus for CTF correction with Ctfplotter'):
            return 1

   return 0


# Do correction with ctfphaseflip
def CTFCorrectAlignedStack():

   # Write the simple defocus file and use it if there is no defocus file; but if there
   # is, make sure it is in the com file
   focFileName = dataName + '.defocus'
   simpleName = dataName + '_simple.defocus'
   if not os.path.exists(focFileName):
      if writeTextFileReportErr(simpleName, [fmtstr('{} {} 0. 0. {}', zsize // 2,
                                                    zsize // 2, defocus)]):
         return 1
      sedcom = [sedModify('DefocusFile', simpleName)]
   else:
      sedcom = [sedModify('DefocusFile', focFileName)]

   sedcom.append(sedModify('PixelSize', aliBinning * pixelSize))
   
   comfile = 'ctfcorrection' + axisCom
   ctfLines = readTextFileReportErr(comfile)
   if not ctfLines:
      return 1
   if pysed(sedcom, ctfLines, comfile, retErr=True):
      abortSet('Error modifying ' + comfile)
      return 1
   if parallelCPU > 1:
      target = 2 * parallelCPU
      maxSlices = (zsize + target - 1) / target
      try:
         runcmd(fmtstr('splitcorrection -m {} {}', maxSlices, comfile))
      except ImodpyError:
         reportImodError('Error trying to run ctfcorrection in parallel')
         return 1
   
   if runOneProcess(comfile, parallelCPU < 2,
                    message = 'Correcting for CTF with Ctfphaseflip'):
      return 1

   if useFileAsReplacement(dataName + '_ctfcorr.ali', dataName + '.ali', False, True):
      return 1

   return 0
      

# Optionally detect gold for erasing with 3D method
def detectGoldIn3D():
   global eraseGold
   
   eraseGold = lookupDirective(runtimePrefix + 'AlignedStack', 'eraseGold', 0, INT_VALUE)
   if isinstance(eraseGold, str):
      abortSet('Error converting eraseGold entry to integer')
      return 1

   # Get the binning or use the binning that etomo would assign, bead size / 5 rounded
   # to an integer with a minimum binned size of 4
   if eraseGold > 1 and needStep(detect3DstepNum):
      binning = lookupDirective(runtimePrefix + 'GoldErasing', 'binning', 0, INT_VALUE)
      if not binning:
         binning = int(round(fidSizePix / fb3dOptimalBinnedSize))
         if binning > 1 and fidSizePix / binning < fb3dMinBinnedSize:
            binning -= 1

      # Get the aligned stack if binning differs
      if binning != aliBinning:
         (comRoot, process) = comAndProcessForAlignedStack('')
         comlines = ['InputFile ' + comRoot + axisCom,
                     'BinningOfImages ' + str(binning),
                     'RootNameOfDataFiles ' + dataName]
         if not ifMontage:
            comlines.append(fmtstr('OneParameterChange {}newst_3dfind{}.newstack.' + \
                                      'SizeToOutputInXandY={},{}', comPrefix, axisLet,
                                   aliXunbinned // binning, aliYunbinned // binning))
         comlines += laterComDirectives(comRoot + '_3dfind', process, 0)
         if makeAndRunOneCom(comlines, comRoot + '_3dfind' + axisCom,
                             'Making aligned stack for erasing gold'):
            return 1

      # Set up to get the reconstruction
      # use fid alignment if two surfaces, otherwise there needs to be a directive
      if numSurfaces > 1:
         thickness = 2 * ((int(round(fidThickness + 4. * fidSizePix)) + 1) // 2)
      else:
         thickness = lookupDirective(runtimePrefix + 'GoldErasing', 'thickness', 0,
                                     INT_VALUE)
         if not thickness:
            abortSet('A GoldErasing.thickness directive must be supplied for 3D gold ' + \
                        'finding')
            return 1

      # Get the com file
      comfile = 'tilt_3dfind' + axisCom
      comlines = ['InputFile tilt' + axisCom,
                  'OutputFile ' + comfile,
                  'BinningOfImages ' + str(binning),
                  'RootNameOfDataFiles ' + dataName,
                  'ThicknessToMake ' + str(thickness),
                  'ShiftInY ' + str(fidIncShift)]
      if binning != aliBinning:
         comlines.append('Use3dfindAliInput 1')
      comlines += laterComDirectives('tilt_3dfind', 'tilt', 0)

      try:
         runcmd('makecomfile -StandardInput', comlines)
      except ImodpyError:
         reportImodError('Error making ' + comfile)
         return 1

      # Make the reconstruction
      if splitAndRunTilt(comfile, 'Making tomogram for finding beads'):
         return 1

      # Find the beads
      comlines = ['RootNameOfDataFiles ' + dataName,
                  'BinningOfImages ' + str(binning),
                  'BeadSize ' + str(fidSizePix),
                  fmtstr('OneParameterChange {}findbeads3d{}.findbeads3d.' + \
                            'StorageThreshold=-1', comPrefix, axisLet)]
      if lightBeads:
         comlines.append(fmtstr('OneParameterChange {}findbeads3d{}.findbeads3d.' + \
                                   'LightBeads=1', comPrefix, axisLet))
      comlines += laterComDirectives('findbeads3d', 'findbeads3d', 0)
      if makeAndRunOneCom(comlines, 'findbeads3d' + axisCom, 'Finding beads in tomogram'):
         return 1

   return 0


# Erase gold in aligned stack one way or another
def eraseGoldInAlignedStack():
   if eraseGold > 1:

      # Get the reprojection if using 3D method
      comlines = ['InputFile tilt_3dfind' + axisCom,
                  'RootNameOfDataFiles ' + dataName]
      if makeAndRunOneCom(comlines, 'tilt_3dfind_reproject' + axisCom,
                          'Reprojecting model of beads in tomogram onto aligned stack'):
         return 1

   # Or transform fiducial model
   else:
      if fiducialless:
         abortset('Cannot erase gold with fiducials after fiducialless processing')
      try:
         runcmd(fmtstr('xfmodel -xf {0}.tltxf {0}.fid {0}_erase.fid', dataName))
      except ImodpyError:
         reportImodError('Could not transform fiducials for erasing gold')
         return 1

   # Erase the beads
   extraDiam = lookupDirective(runtimePrefix + 'GoldErasing', 'extraDiameter', 0,
                               FLOAT_VALUE)
   if not extraDiam:
      extraDiam = 0.
   comlines = ['RootNameOfDataFiles ' + dataName,
                  'BeadSize ' + str(fidSizePix / aliBinning + extraDiam)]
   comlines += laterComDirectives('golderaser', 'ccderaser', 0)
   if lookupDirective(comPrefix + 'golderaser', 'ccderaser.ExpandCircleIterations', 0,
                      STRING_VALUE) == None:
      comlines.append(fmtstr('OneParameterChange {}golderaser{}.ccderaser.' + \
                                'ExpandCircleIterations=2', comPrefix, axisLet))
   if makeAndRunOneCom(comlines, 'golderaser' + axisCom,
                       'Erasing beads from aligned stack'):
      return 1
   
   if useFileAsReplacement(dataName + '_erase.ali', dataName + '.ali', False, True):
      return 1

   return 0


# 2D filtering, very simple operation
def filterAlignedStack():
   if lookupDirective(runtimePrefix + 'AlignedStack', 'filterStack', 0, BOOL_VALUE) and \
          needStep(13):
      if runOneProcess('mtffilter' + axisCom, message =
                       '2D filtering the aligned stack with Mtffilter'):
         return 1
      if useFileAsReplacement(dataName + '_filt.ali', dataName + '.ali', False, True):
         return 1

   return 0


# Change many entries in tilt.com for the current situation
def modifyTiltComFile(sampleThickness):
   global xtiltNeeded
   
   comfile = 'tilt' + axisCom
   comlines = readTextFileReportErr(comfile)
   if not comlines:
      return 1

   if sampleThickness:
      thickness = sampleThickness

   else:
      
      # Get different variants on thickness entry and insist on only one
      thickness = lookupDirective(comPrefix + 'tilt', 'tilt.THICKNESS', 0, INT_VALUE)
      binnedThick = lookupDirective(runtimePrefix + 'Reconstruction', 'binnedThickness',
                                    0, INT_VALUE)
      fallbackThick = lookupDirective(runtimePrefix + 'Reconstruction',
                                      'fallbackThickness', 0, INT_VALUE)
      if thickness and binnedThick:
         abortSet('Both tilt.THICKNESS and Reconstruction.binnedThickness were entered')
         return 1
      if thickness and fallbackThick:
         abortSet('Both tilt.THICKNESS and Reconstruction.fallbackThickness were entered')
         return 1
      if fallbackThick and binnedThick:
         abortSet('Both Reconstruction.fallbackThickness and ' +\
                     'Reconstruction.binnedThickness were entered')
         return 1

      if binnedThick:
         thickness = aliBinning * binnedThick

      # If that did not provide a thickness, set it to fallback if there is nothing from
      # the alignment; otherwise take it from the alignment, with possible extra amount
      # but use the fallback if this is too thin
      if not thickness:

         # First look for a thickness from tomopitch
         # Parse this log afresh; results from align log are already in globals
         angleArr = [0, 0., 0., 0.]
         err = parseTomopitchLog(angleArr)
         if err < 0:
            return 1
         if not err:
            thickness = angleArr[0]
            xtiltNeeded = angleArr[1]

         # Or use the align thickness if no positioning available
         elif reconThickness:
            thickness = 2 * ((int(round(reconThickness)) + 1) // 2)

         # In either case, add the extra thickness if defined
         if thickness:
            extra = lookupDirective(runtimePrefix + 'Reconstruction', 'extraThickness', 0,
                                    INT_VALUE)
            if testDirectiveValue(extra, 'Reconstruction.extraThickness', 'integer'):
               return 1
            if extra:
               thickness += extra
               
         # In any of these cases, fallback rules if thickness is too low or not set
         if fallbackThick and thickness < fallbackThick * useFallbackRatio:
            thickness = fallbackThick

         if not thickness:
            abortSet('No thickness was specified and neither fiducial alignment nor ' + \
                        'positioning gave a thickness to use')
            return 1

                  
   if ifMontage:
      fullx = montFrameData[6]
      fully = montFrameData[7]
      sssx = montFrameData[8]
      sssy = montFrameData[9]
   else:
      fullx = rawXsize
      fully = rawYsize
      sssx = -((aliXunbinned - rawXsize) // 2)
      sssy = -((aliYunbinned - rawYsize) // 2)

   gpuVal = -1
   if useGPU:
      gpuVal = 0
   sedcom = [sedModify('IMAGEBINNED', aliBinning),
             sedModify('XAXISTILT', xtiltNeeded),
             sedModify('FULLIMAGE', fmtstr('{} {}', fullx, fully)),
             sedModify('SUBSETSTART', fmtstr('{} {}', sssx, sssy)),
             sedModify('THICKNESS', thickness)] + \
             sedDelAndAdd('UseGPU', gpuVal, 'XTILTFILE')
   if not axisNum:
      sedcom.append(sedModify('OutputFile', setName + '_full.rec'))
   if useGPU:
      sedcom += sedDelAndAdd('ActionIfGPUFails', '1,2', 'XTILTFILE');
   else:
      sedcom.append('/^ActionIfGPUFails/d')
   if didLocalAlign:
      sedcom += sedDelAndAdd('LOCALFILE', dataName + 'local.xf', 'XTILTFILE')
   else:
      sedcom.append('/^LOCALFILE/d')
   if madeZfactors:
      sedcom += sedDelAndAdd('ZFACTORFILE', dataName + '.zfac', 'XTILTFILE')
   else:
      sedcom.append('/^ZFACTORFILE/d')

   # Handle change in scaling if they turned off log and did not supply a scale
   logbase = optionValue(comlines, 'LOG', FLOAT_VALUE)
   if not logbase and not lookupDirective(comPrefix + 'tilt', '.tilt.SCALE', 0,
                                          STRING_VALUE):
      scaleArr = optionValue(comlines, 'SCALE', FLOAT_VALUE)
      if not scaleArr or len(scaleArr) < 2:
         abortSet('Cannot modify SCALE value in tilt' + axisLet + '.com for linear ' +\
                     'scaling')
         return 1

      # Copytomocoms produces scales from 1000 to 40 depending on X size.
      # Linear requires scale to be reduced by 5000, giving numbers from 0.2 to 0.008
      # 3 is a safe dividing point for deciding whether this has already happened
      if scaleArr[1] > 3.:
         sedcom.append(sedModify('SCALE', fmtstr('{} {:.3f}',
                                                 scaleArr[0], scaleArr[1] / 5000.)))

   if pysed(sedcom, comlines, comfile, retErr=True):
      abortSet('Error modifying ' + comfile)
      return 1
   return 0
   

# Make tomogram by backprojection and/or SIRT
def generateTomogram():
   doSIRT = lookupDirective(runtimePrefix + 'Reconstruction', 'useSirt', 0, BOOL_VALUE)
   doBPalso = lookupDirective(runtimePrefix + 'Reconstruction', 'doBackprojAlso', 0,
                              BOOL_VALUE)
   if doBPalso or not doSIRT:
      if splitAndRunTilt('tilt' + axisCom, 'Making tomogram by back-projection'):
         return 1

   if doSIRT:
      numProc = 1
      if parallelGPU > 1:
         numProc = parallelGPU
      elif parallelCPU and not useGPU:
         numProc = parallelCPU
      comlines = laterComDirectives('sirtsetup', 'sirtsetup', 0)
      comlines.append(fmtstr('OneParameterChange {}sirtsetup{}.sirtsetup.' + \
                                'NumberOfProcessors={}', comPrefix, axisLet, numProc))
      if makeAndRunOneCom(comlines, 'sirtsetup' + axisCom,
                          'Making command files to run SIRT'):
         return 1
      if runOneProcess('tilt' + axisLet + '_sirt.com', False, useGPU, message =
                       'Making tomogram with SIRT'):
         return 1

   return 0


# Run positioning (with whole tomogram for now)
def positionTomogram():
   numScales = [4, 2, 2, 1]
   boxSizes = [32, 20, 16, 12]
   blockSizes = [100, 60, 48, 36]
   sampleType = lookupDirective(runtimePrefix + 'Positioning', 'sampleType', 0, INT_VALUE)
   if testDirectiveValue(sampleType, 'Positioning.sampleType', 'integer'):
      return 1
   if sampleType > 1:
      prnLog('The directive Positioning.sampleType can only be 1 to do positioning')
      return 0
   if not sampleType:
      return 0

   # Get binning and make aligned stack
   size = max(rawXsize, rawYsize)
   aliBinning = lookupDirective(runtimePrefix + 'Positioning', 'binByFactor', 0,
                                INT_VALUE)
   if testDirectiveValue(aliBinning, 'Positioning.binByFactor', 'integer'):
      return 1
   if not aliBinning:
      for bin in (1, 2, 3, 4):
         if size / bin < positionBinningTarget or bin == 4:
            aliBinning = bin
            prnLog('Binning for positioning tomogram set to ' + str(aliBinning))
            break
      
   if makeAlignedStack(aliBinning):
      return 1

   # Get thickness and make tomogram
   thickness = lookupDirective(runtimePrefix + 'Positioning', 'thickness', 0, INT_VALUE)
   if testDirectiveValue(thickness, 'Positioning.thickness', 'integer'):
      return 1
   if not thickness:
      for ind in range(len(dfltPosThicknesses) - 1, -1, -1):
         if size > sizesForPosThicknesses[ind]:
            thickness = dfltPosThicknesses[ind]
            prnLog('Thickness for positioning tomogram set to ' + str(thickness))
            break
         
   if modifyTiltComFile(thickness) or \
          splitAndRunTilt('tilt' + axisCom, 'Making tomogram for positioning'):
      return 1

   # Run findsection to get the model
   if runFindSection(dataName + '.rec', numScales[aliBinning - 1],
                     boxSizes[aliBinning - 1], pitchMod = 'tomopitch' + axisLet + '.mod',
                     block = blockSizes[aliBinning - 1]):
      prnLog('Finding the section for positioning did not work; proceeding if possible')
      return 0

   # Get existing Z shift, angle offset, and X tilt
   tiltLines = readTextFileReportErr('tilt' + axisCom)
   if not tiltLines:
      return 1
   zShiftOrig = 0.
   angleOffsetOrig = 0.
   if fiducialless:
      zShiftArr = optionValue(tiltLines, 'SHIFT', FLOAT_VALUE, numVal = 2)
      if zShiftArr and len(zShiftArr) > 1:
         zShiftOrig = zShiftArr[1]
      offset = optionValue(tiltLines, 'OFFSET', FLOAT_VALUE, numVal = 1)

   else:
      alignLines = readTextFileReportErr('align' + axisCom)
      if not alignLines:
         return 1
      zShift = optionValue(alignLines, 'AxisZShift', FLOAT_VALUE, numVal = 1)
      if zShift:
         zShiftOrig = zShift
      offset = optionValue(alignLines, 'AngleOffset', FLOAT_VALUE, numVal = 1)

   if offset:
      angleOffsetOrig = offset
   xtiltOrig = 0.
   xtilt = optionValue(tiltLines, 'XAXISTILT', FLOAT_VALUE, numVal = 1)
   if xtilt:
      xtiltOrig = xtilt

   # Modify tomopitch and run it
   sedcom = sedDelAndAdd('ScaleFactor', aliBinning, 'ModelFile') + \
       sedDelAndAdd('AngleOffsetOld', angleOffsetOrig, 'ModelFile') + \
       sedDelAndAdd('ZShiftOld', zShiftOrig, 'ModelFile') + \
       sedDelAndAdd('XAxisTiltOld', xtiltOrig, 'ModelFile')
   if modifyWriteAndRunCom('tomopitch' + axisCom, sedcom,
                           message = 'Finding angles and thickness'): 
      return 1

   # Parse this log
   angleArr = [0, 0., 0., 0.]
   err = parseTomopitchLog(angleArr)
   if err < 0:
      return 1
   (thickness, xtilt, offset, zShift) = angleArr
   if err or not thickness:
      prnLog('Tomopitch did not produce a good result; proceeding if possible')
      return 0
   
   # Write tilt.com with the X-axis tilt and shift/angle offset for fidless
   prnLog(fmtstr('Positioning gave thickness {}, X-axis tilt {:.2f}, angle offset ' + \
                    '{:.2f}, Z shift {:.1f}', thickness, xtilt, offset, zShift))
   sedcom = [sedModify('XAXISTILT', xtilt), 
             sedModify('THICKNESS', thickness)]
   if fiducialless:
      sedcom += sedDelAndAdd('OFFSET', offset, 'OutputFile') + \
          sedDelAndAdd('SHIFT', '0. ' + str(zShift), 'OutputFile')
   if pysed(sedcom, tiltLines, 'tilt' + axisCom, retErr=True):
      abortSet('Error modifying tilt' + axisCom)
      return 1

   # Write align.com with Z shift and offset and run it
   if not fiducialless:
      sedcom = [sedModify('AxisZShift', zShift),
                sedModify('AngleOffset', offset)]
      if modifyWriteAndRunCom('align' + axisCom, sedcom, alignLines,
                              'Doing final alignment with new position'): 
         return 1

   return 0
      

# COMBINE FUNCTIONS
#
# Get the final patch size and extra targets for autopatchfid
def getAutoPatchfitParams():
   extraTargets = lookupDirective(combinePrefix, 'extraTargets', 0, STRING_VALUE)
   finalPatchSize = lookupDirective(combinePrefix, 'finalPatchSize', 0, STRING_VALUE)
   if not extraTargets:
      extraTargets = dfltExtraWarpTargets
   if not finalPatchSize:
      finalPatchSize = dfltFinalPatchSize
   return (finalPatchSize, extraTargets)


# Generate two sed commands for adding an edf file entry, deleting if necessary
def edfDelAndAdd(option, value, delim = '/'):
   return [fmtstr('{0}{1}={0}d', delim, option),
           fmtstr('{0}{1}{0}a{0}{2}={3}{0}', delim, 'Setup.DatasetName=', option, value)]


# Analyze the tomogram for Z limits and run setupcombine
def setupCombine():
   global axisLet, axisNum, useVolMatch, nxRecA, nyRecA
   topBotInd = 2
   patchSize = 'M'
   useVolMatch = 0
   edfVol = 'false'
   if fiducialless or patchTrack or not os.path.exists('transferfid.coord'):
      useVolMatch = 1
      edfVol = 'true'

   # Get the right files in place if SIRT is involved
   useSIRTifBoth = lookupDirective(combinePrefix, 'doSIRTifBoth', 0, INT_VALUE)
   if testDirectiveValue(useSIRTifBoth, 'Combine.doSIRTifBoth', 'integer'):
      return 1
   recRoot = setName + 'a'
   for axisNum in (1, 2):
      recName = recRoot + '.rec'
      (doSIRT, doBoth, SIRTname) = getSIRTrecName(recRoot)
      useSIRT = doSIRT and (useSIRTifBoth or not doBoth)
      if useSIRT:
         SIRTexists = os.path.exists(SIRTname)
         recExists = os.path.exists(recName)
         bpName = recRoot + '_BP.rec'
         if recExists and not SIRTexists:
            prnLog('The file ' + recName + ' exists and the SIRT reconstruction ' + \
                      SIRTname + ' does not; assuming it was already renamed')
         elif not SIRTexists:
            abortSet('Neither the SIRT reconstruction ' + SIRTname + ' nor the file ' + \
                        recName + ' exist; cannot proceed')
            return 1
         else:
            if recExists and doBoth:
               if useFileAsReplacement(recName, bpName, False, True):
                  return 1
               prnLog('Renamed back-projection reconstruction ' + recName + ' to: ' + \
                         bpName)
            if useFileAsReplacement(SIRTname, recName, False, True):
               return 1
            prnLog('Renamed SIRT reconstruction ' + SIRTname + ' to: ' + recName)

      recRoot = setName + 'b'

   axisNum = 0

   # Get the directives and use the defaults if none
   matchAtoBratio = lookupDirective(combinePrefix, 'matchAtoBThickRatio', 0, FLOAT_VALUE)
   if testDirectiveValue(matchAtoBratio, 'Combine.matchAtoBThickRatio', 'float'):
      return 1
   if not matchAtoBratio:
      matchAtoBratio = dfltMatchAtoBratio
   numScales = lookupDirective(combinePrefix, 'findSecNumScales', 0, INT_VALUE)
   if testDirectiveValue(numScales, 'Combine.findSecNumScales', 'integer'):
      return 1
   if not numScales:
      numScales = dfltCombineNumScales
   boxSize = lookupDirective(combinePrefix, 'findSecBoxSize', 0, INT_VALUE)
   if testDirectiveValue(boxSize, 'Combine.findSecBoxSize', 'integer'):
      return 1
   if not boxSize:
      boxSize = dfltCombineBoxSize

   # Need to find limits in A unless match ratio is very high
   needFindA = matchAtoBratio < 4.
   if needFindA:
      topBotA = 6 * [0]
      if runFindSection(setName + 'a.rec', numScales, boxSize, topBots = topBotA):
         return 1
      zRangeA = topBotA[topBotInd + 1] - topBotA[topBotInd]
      if zRangeA < 4:
         abortSet('Findsection failed to find a useful Z range in A tomogram')

   # Need to find limits in B unless match ratio is very low
   needFindB = matchAtoBratio > 0.25
   if needFindB:
      topBotB = 6 * [0]
      if runFindSection(setName + 'b.rec', numScales, boxSize, topBots = topBotB):
         return 1
      zRangeB = topBotB[topBotInd + 1] - topBotB[topBotInd]
      if zRangeB < 4:
         abortSet('Findsection failed to find a useful Z range in B tomogram')

   # Match A to B if ratio was very high or B is sufficiently smaller
   matchAtoB = not needFindA or (needFindB and zRangeB <= matchAtoBratio * zRangeA)
   edfMatch = 'B_to_A'
   if matchAtoB:
      topBotA = topBotB
      edfMatch = 'A_to_B'
      
   # Determine number of surfaces, make sure 2 is still OK
   # If in doubt, just set to 1 and see what happens
   numSurf = numSurfaces
   if useVolMatch:
      numSurf = 2
   else:
   
      # Do the appropriate axis of align log
      if matchAtoB:
         axisLet = 'b'
      angleArr = [0., 0., 0., 0., 0., 0., 0, 0]
      if analyzeAlignLog(numSurfaces > 1, angleArr):
         return 1
      axisLet = 'a'
      (totalDelTilt, xtiltNeeded, fidThickness, fidIncShift, fidTotalShift, \
          reconThickness, numBot, numTop) = angleArr
      if numBot + numTop < solvematchMinFids:
         useVolMatch = 1
         prnLog('Using Dualvolmatch instead of Solvematch because there are too few ' +\
                   'fiducials')
      elif numSurf > 1:
         if fidThickness < (topBotA[topBotInd + 1] - topBotA[topBotInd]) / 2:
            numSurf = 1
            mess = 'because fiducial extent is much smaller than Z range'
         else:
            fallbackThick = lookupDirective(runtimePrefix + 'Reconstruction',
                                            'fallbackThickness', 0, INT_VALUE)
            if isinstance(fallbackThick, int) and \
                   reconThickness < fallbackThick * useFallbackRatio:
               numSurf = 1
               mess = 'because fiducial extent is much smaller than fallback thickness'

         if numSurf > 1 and (numBot < solvematchMinEachSide or \
                                numTop < solvematchMinEachSide or \
                                min(float(numBot) / numTop, float(numTop) / numTop) < \
                                solvematchMinSideRatio):
            numSurf = 1
            mess = 'because there are too few fiducials on one surface'

         if numSurf == 1:
            prnLog('Setting number of surfaces for Solvematch to 1 ' + mess)

   edfSurf = 'BothSides'
   if numSurf == 1:
      edfSurf = 'OneSide'
      
   # Get the rest of the combine setup directives
   # TODO: what if there is a blank directive to cancel extra targets?
   patchIn = lookupDirective(combinePrefix, 'patchSize', 0, STRING_VALUE)
   if patchIn:
      patchSize = patchIn
   (finalPatchSize, extraTargets) = getAutoPatchfitParams()
   
   wedgeFrac = lookupDirective(combinePrefix, 'wedgeReduction', 0, FLOAT_VALUE)
   lowRadius = lookupDirective(combinePrefix, 'lowFromBothRadius', 0, FLOAT_VALUE)
   if testDirectiveValue(wedgeFrac, 'Combine.wedgeReduction', 'float') or \
          testDirectiveValue(lowRadius, 'Combine.lowFromBothRadius', 'float'):
      return 1
   comLines = ['RootName ' + setName,
               'WarningsToStandardOut 1',
               'TransferPointFile transferfid.coord',
               'SurfaceModelType ' + str(numSurf),
               fmtstr('ZLowerAndUpper {},{}', topBotA[topBotInd], topBotA[topBotInd + 1]),
               'PatchTypeOrXYZ ' + patchSize,
               'AutoPatchFinalSize ' + finalPatchSize,
               'ExtraResidualTargets ' + extraTargets]
   if useVolMatch:
      comLines.append('InitialVolumeMatching 1')
   if scopeTmplText in allDirectives[BatInd]:
      comLines.append('ChangeParametersFile ' + allDirectives[BatInd][scopeTmplText][0])
   if sysTmplText in allDirectives[BatInd]:
      comLines.append('ChangeParametersFile ' + allDirectives[BatInd][sysTmplText][0])
   if userTmplText in allDirectives[BatInd]:
      comLines.append('ChangeParametersFile ' + allDirectives[BatInd][userTmplText][0])
   comLines.append('ChangeParametersFile ' + absDirectiveFile)
   if matchAtoB:
      comLines.append('MatchAtoB 1')
   if wedgeFrac:
      comLines.append('WedgeReductionFraction ' + str(wedgeFrac))
   if lowRadius:
      comLines.append('LowFromBothRadius ' + str(lowRadius))

   try:
      runcmd('setupcombine -StandardInput', comLines, 'stdout')
   except ImodpyError:
      reportImodError('Error running setupcombine')
      return 1

   # Now try to modify the edf file.  Z limits are fatal.  First word -> batchruntomo
   sedcom = edfDelAndAdd('batchruntomo.Combine.MatchMode', edfMatch) + \
       edfDelAndAdd('batchruntomo.Combine.FiducialMatch', edfSurf) + \
       edfDelAndAdd('batchruntomo.Combine.InitialVolumeMatching', edfVol) + \
       edfDelAndAdd('batchruntomo.Combine.PatchSize', patchSize) + \
       edfDelAndAdd('batchruntomo.Combine.FinalPatchSize', finalPatchSize) + \
       edfDelAndAdd('batchruntomo.Combine.ExtraResidualTargets', extraTargets)

   edfFile = setName + '.edf'
   makeBackupFile(edfFile)
   if pysed(sedcom, edfFile + '~', edfFile, retErr = True):
      abortSet('Error modifying ' + edfFile)
      return 1

   # Finally, modify matchvol1.com to preserve a larger B volume size
   # The transposed ny,nz match setupcombine usage for better or worse
   try:
      (nxRecA, nza, nyRecA) = getmrcsize(setName + 'a.rec')
      (nxb, nzb, nyb) = getmrcsize(setName + 'b.rec')

   except ImodpyError:
      reportImodError('Error getting sizes of axis rec files')
      return 1

   sedcom = [sedModify('OutputSizeXYZ', fmtstr('{} {} {}', nxRecA, max(nza, nzb),
                                               nyRecA))]
   if pysed(sedcom, 'matchvol1.com', 'matchvol1.com', retErr = True):
      abortSet('Error modifying matchvol1.com')
      return 1
      
   return 0


# Run solvematch and make needed modifications if there is a center shift
def initialCombineMatch():
   global suppressAbort, useVolMatch

   # If we are coming in at this step, need to reconstruct whether volume matching
   # is supposed to be used
   if useVolMatch < 0:
      edfLines = readTextFileReportErr(setName + '.edf')
      if not edfLines:
         return 1
      for line in edfLines:
         if 'InitialVolumeMatching' in line:
            if 'true' in line:
               useVolMatch = 1
            elif 'false' in line:
               useVolMatch = 0
            break
      if useVolMatch < 0:
         abortSet('Cannot determine if initial volume matching was set up to be used')
         return 1

   # Set up for type of process and whether may need to run it twice
   if useVolMatch:
      comRoot = 'dualvolmatch'
      numLoop = 1
      tags = [('unbinned mean residual', 4), ('implies a center', 4), ('Falling back', 4)]
   else:
      comRoot = 'solvematch'
      numLoop = 2
      tags = [('Mean residual', 4), ('Scaling along', 0), ('Local fits', 0),
              ('Average mean', 4)]

   for loop in range(numLoop):

      # Run the process and process and read log regardless
      suppressAbort = True
      err = runOneProcess(comRoot + '.com', message = 'Getting initial alignment ' +\
                             'between volumes')
      suppressAbort = False

      # Warnings got printed regardless, errors got printed if it failed, so set tags to
      # avoid duplicate messages
      useTags = [('ERROR:', 0)] + tags
      if err:
         useTags = tags
      printTaggedMessages(comRoot + '.log', useTags);
      logLines = readTextFileReportErr(comRoot + '.log')
      if not logLines:
         return 1

      # For vol match, see if need to change the matchvol thickness
      if useVolMatch and not err:
         for line in logLines:
            if 'may need to set thickness' in line:
               lsplit = line.split()
               try:
                  newThick = int(lsplit[-1])
               except Exception:
                  abortSet('Error trying to get suggested thickness for matchvol')

               sedcom = [sedModify('OutputSizeXYZ', fmtstr('{} {} {}', nxRecA,
                                                              newThick, nyRecA))]
               if pysed(sedcom, 'matchvol1.com', 'matchvol1.com', retErr = True):
                  abortSet('Error modifying matchvol1.com')
                  return 1
               prnLog(fmtstr('Thickness for matched volume set to {} as suggested',
                             newThick))
               break

      # For solvematch look first to see if it suggests using one surface, modify the
      # com and loop for another run
      if not useVolMatch:
         redo = False
         for line in logLines:
            if 'Try specifying' in line and 'on one surface' in line:
               if pysed([sedModify('SurfacesOrUseModels', 1)], 'solvematch.com',
                        'solvematch.com', retErr = True):
                  abortSet('Error modifying solvematch.com')
                  return 1
               prnLog('Rerunning with one surface as suggested')
               redo = True
               break

         if redo:
            continue
            
      # Otherwise done if no error
      if not err:
         return 0
      initShift = []
      shiftLimit = 0

      # If there was an error, try to find initial shift as well as center shift
      for line in logLines:

         if 'InitialShiftXYZ' in line and 'needs' in line:
            lsplit = line.split()
            try:
               for ind in (0, 1, 2):
                  initShift.append(int(lsplit[-3 + ind]))
            except Exception:
               abortSet('Error trying to get initial shift from :' + line)
         if 'CenterShiftLimit' in line and 'avoid stopping' in line:
            lsplit = line.split()
            try:
               shiftLimit = int(lsplit[-1])
            except ValueError:
               pass

         # If error line is found that says it's OK, modify patchcorr.com
         if 'ERROR:' in line and (('INITIAL SHIFT' in line and \
                                      'SOLUTION IS OK' in line) or \
                                     'Initial shift needs' in line):
            if initShift:
               prnLog(fmtstr('Setting initial shift for Corrsearch3d to {} {} {}',
                             initShift[0], initShift[2], initShift[1]))
               sedcm = sedDelAndAdd('InitialShiftXYZ', fmtstr('{},{},{}', initShift[0],
                                                              initShift[1], initShift[2]),
                                    'FlipYZMessages')
               if pysed(sedcm, 'patchcorr.com', 'patchcorr.com', retErr = True):
                  abortSet('Error modifying patchcorr.com')
                  return 1

               # If that succeeded, modify com file with shift limit
               if shiftLimit:
                  if pysed([sedModify('CenterShiftLimit', shiftLimit)], comRoot + '.com',
                           comRoot + '.com', retErr = True):
                     abortSet('Error modifying solvematch.com with new shift limit')
                     return 1
               return 0

            abortSet('Initial shift is required to go on, but was not found in ' +\
                        comRoot + '.log')
            return 1

   abortSet('Error getting initial alignment between volumes')
   return 1
   

# Run matchvol, autopatchfit, and volcombine
def alignAndCombineAxes():
   if needStep(17) and runOneProcess('matchvol1.com', useMostCPUs = True,
                                     message = 'Making initial matching volume'):
      return 1

   if needStep(18):
      (finalPatchSize, extraTargets) = getAutoPatchfitParams()
      comLines = ['$autopatchfit -StandardInput',
                  'FinalPatchTypeOrXYZ ' + finalPatchSize]
      if extraTargets:
         comLines.append('ExtraResidualTargets ' + extraTargets)
      if writeTextFileReportErr('autopatchfit.com', comLines):
         return 1
      err = runOneProcess('autopatchfit.com', message = 'Doing patch correlation ' +\
                             'and fitting to local patches', useMostCPUs = True)
      printTaggedMessages('autopatchfit.log', standardTags +
                          [('Using ', 4), ('Changing ', 4), ('Adding ', 4),
                           ('FINDWARP -', 0), ('found a good', 4)])
      if err:
         abortSet('Cannot align the two tomograms')
         return 1

   if needStep(19) and runOneProcess('volcombine.com', 
                                     message = 'Combining the two volumes'):
      return 1
      

# Run trimvol if ANY of the directives are present
def trimVolume():
   trimPrefix = runtimePrefix + 'Trimvol'
   sizeKeys = ('sizeInX', 'sizeInY', 'thickness', 'scaleFromX', 'scaleFromY', 
               'scaleFromZ', 'findSecAddThickness')
   if lookupDirective(trimPrefix, 'reorient', 0, INT_VALUE) == None:
      for key in sizeKeys:
         if lookupDirective(trimPrefix, key, 0, FLOAT_VALUE) != None:
            break
      else:    # ELSE ON FOR
         return 0

   if axisNum > 0 and not lookupDirective(trimPrefix, 'doAorBofDualAxis', 0, BOOL_VALUE):
      return 0

   useFindSec = lookupDirective(trimPrefix, 'findSecAddThickness', 0, FLOAT_VALUE) != None
   if lookupDirective(trimPrefix, 'thickness', 0, FLOAT_VALUE) != None and useFindSec:
      abortSet('Cannot use both Trimvol.findSecAddThickness and Trimvol.thickness' + \
                  ' directives')
      return 1
      
   reorient = lookupDirective(trimPrefix, 'reorient', 0, INT_VALUE)
   if reorient == None:
      reorient = 2
   if isinstance(reorient, str) or reorient < 0 or reorient > 2:
      abortSet('The value for "reorient" must be 0, 1, or 2')
      return 1
   
   # Figure out what volume to trim and get its size
   recRoot = dataName
   trimNames = [dataName + '.rec']
   if dualAxis and axisNum > 0:
      trimNames = [dataName + '_trim.rec']
   elif dualAxis:
      recRoot = 'sum'
   else:
      recRoot = dataName + '_full'
   recNames = [recRoot + '.rec']

   if not dualAxis or axisNum > 0:
      (doSIRT, doBoth, SIRTname) = getSIRTrecName(recRoot)
      if doSIRT:
         useSIRT = True
         if doBoth:
            trimBoth = lookupDirective(trimPrefix, 'doSIRTifBoth', 0, INT_VALUE)
            if testDirectiveValue(trimBoth, 'Trimvol.doSIRTifBoth', 'integer'):
               return 1
            useSIRT = trimBoth > 0

         if useSIRT:
            if not SIRTname:
               abortSet('Cannot trim SIRT output, cannot find LeaveIterations directive')
               return 1

            recNames = [SIRTname]
            if doBoth and trimBoth > 1:
               recNames.append(recRoot + '.rec')
               trimNames.append(trimNames[0][0:-4] + '_BP.rec')

   for name in recNames:
      if not os.path.exists(name):
         abortSet('The file to be trimmed, ' + name + ', does not exist')
         return 1
   try:
      (nxrec, nzrec, nyrec) = getmrcsize(recNames[0])
   except ImodpyError:
      reportImodError('Could not get size of volume to trim')
      return 1
   
   # Determine size parameters, convert fractions, and check them
   sizesScales = []
   baseVals = (nxrec, nyrec, nzrec, nxrec, nyrec, nzrec, nzrec)
   for key in sizeKeys:
      val = lookupDirective(trimPrefix, key, 0, FLOAT_VALUE)
      if testDirectiveValue(val, 'Trimvol.' + key, 'float'):
         return 1
      size = None
      if val != None:
         base = baseVals[len(sizesScales)]
         lowLim = 40
         if len(sizesScales) % 3 == 2:
            lowLim = 4
         size = int(round(val))
         if size <= 1.:
            size = int(round(val * base))
         if (len(sizesScales) < 6 and (val < 0.02 or size < lowLim or size > base)) or \
                (len(sizesScales) == 6 and (size < 0 or size > base)):
            abortSet('The size specified by the "Trimvol.' + key + \
                     '" directive is out of the allowed range')
            return 1
      
      sizesScales.append(size)

   # Run findsection on the BP file if any
   if useFindSec:
      zLimits = 6 * [0]
      if runFindSection(recNames[-1], 4, 32, topBots = zLimits):
         return 1
      if zLimits[5] - zLimits[4] <= 0:
         abortSet('Findsection on ' + recNames[-1] + \
                     ' did not find limits for the section')
         return 1

   # Set up size options in command
   trimcom = '$trimvol -f'
   if reorient == 1:
      trimcom += ' -yz'
   elif reorient == 2:
      trimcom += ' -rx'
   if sizesScales[0]:
      trimcom += ' -nx ' + str(sizesScales[0])
   if sizesScales[1]:
      trimcom += ' -ny ' + str(sizesScales[1])
   if sizesScales[2]:
      trimcom += ' -nz ' + str(sizesScales[2])
   if useFindSec:
      trimcom += fmtstr(' -z {},{}', max(1, zLimits[4] - sizesScales[6]),
                        min(nzrec, zLimits[5] + sizesScales[6]))
      
   # If any scaling is specified, add options.  Set default for Z, leave others at
      # trimvol defaults
   if sizesScales[3] or sizesScales[4] or sizesScales[5]:
      if not sizesScales[5]:
         sizesScales[5] = min(nzrec, max(4, nzrec // 3))
      for ind in range(3, 6):
         if sizesScales[ind]:
            start = 1 + (baseVals[ind] - sizesScales[ind]) // 2
            end = start + sizesScales[ind] - 1
            trimcom += fmtstr(' -s{} {},{}', chr(ord('x') + ind - 3), start, end)

   # Do one or two volumes
   for ind in range(len(recNames)):
      prnLog('Running trimvol on ' + recNames[ind] + ' to create ' + trimNames[ind],
             flush=True)
      if writeTextFileReportErr('trimvol' + axisCom,
                                [trimcom + ' ' + recNames[ind] + ' ' + trimNames[ind]]):
         return 1
      if runOneProcess('trimvol' + axisCom):
         return 1
      
   return 0


# Run anisotropic diffusion in chunks
def runNAD():
   recFile = setName + '.rec'
   nadFile = recFile + '.nad'
   comFile = 'autoNAD' + '.com'

   # Get the directives and make sure both are there, and make sure file exists
   iterations = lookupDirective(runtimePrefix + 'NAD', 'iterations', 0, INT_VALUE)
   Kvalue = lookupDirective(runtimePrefix + 'NAD', 'Kvalue', 0, FLOAT_VALUE)
   if testDirectiveValue(iterations, 'NAD.iterations', 'integer') or \
          testDirectiveValue(iterations, 'NAD.Kvalue', 'float'):
      return 1
   if not iterations and not Kvalue:
      return 0
   if (iterations and not Kvalue) or (Kvalue and not iterations):
      abortSet('Both "iterations" and "Kvalue" directives need to be present to run NAD')
      return 1
   if not os.path.exists(recFile):
      abortSet('You must run post-processing in order to run NAD')
      return 1

   # Get optional memory entry, compute the chunksize, write the dummy com file
   memory = lookupDirective(runtimePrefix + 'NAD', 'chunkMemoryMB', 0, INT_VALUE)
   if testDirectiveValue(iterations, 'NAD.chunkMemoryMB', 'integer'):
      return 1
   if not memory:
      memory = 512
   chunkSize = max(5, memory // 36)
   nadcom = fmtstr('$nad_eed_3d -n {} -k {} INPUTFILE OUTPUTFILE', iterations, Kvalue)
   if writeTextFileReportErr(comFile, [nadcom]):
      return 1

   # Make the chunk coms
   padding = max(8, iterations)
   chunkCom = fmtstr('chunksetup -m {} -p {} -no {} {} {}', chunkSize, padding, comFile,
                     recFile, nadFile)
   try:
      runcmd(chunkCom)
   except ImodpyError:
     reportImodError('Error running chunksetup on ' + comFile)
     return 1

   return runOneProcess(comFile, False, message = 'Filtering with anisotripoc diffusion')
   

# Do all the operations on an axis
def runOneAxis():
   global xtiltNeeded, fidThickness, fidIncShift, reconThickness
   global numSurfaces
   xtiltNeeded, fidThickness, fidIncShift, reconThickness = 0., 0., 0., 0.
   clipLines = []
   
   if getAxisInitialParameters():
      return 1
   
   # Xray removal
   if lookupDirective(runtimePrefix + 'Preprocessing', 'removeXrays', 0, BOOL_VALUE) and \
          needStep(1):

      xrayMess = 'Removing X-rays with Ccderaser'
      sedcom = []

      # Copy the model file to the standard local name and switch to that unless the
      # file already exists.  But do it with imodtrans to make sure pixel size fits the
      # current stack
      model = lookupDirective(comPrefix + 'eraser', 'ccderaser.ModelFile', 0,STRING_VALUE)
      if model:
         eraseMod = setName + axisLet + '.erase'
         if os.path.basename(model) != eraseMod and not os.path.exists(eraseMod):
            try:
               runcmd(fmtstr('imodtrans -I "{}" "{}" "{}"', setName + axisLet + '.st',
                             model, eraseMod))
            except ImodpyError:
               reportImodError('Error transforming manual erasing model ' + model + \
                                  ' to ' + eraseMod)
               return 1
            sedcom = [sedModify('ModelFile', eraseMod)]

      if sedcom:
         if modifyWriteAndRunCom('eraser' + axisCom, sedcom, message = xrayMess):
            return 1
      else :
         if runOneProcess('eraser' + axisCom, message = xrayMess):
            return 1

      # Get clip stats output for fixed stack
      try:
         (tmpX, tmpY, rawZ) = getmrcsize(dataName + '.st')
      except ImodpyError:
         reportImodError('Could not get size of raw stack')
         return 1
      length = min(30, max(15, rawZ // 4))
      montOpt = ''
      if ifMontage:
         montOpt = '-P ' + dataName + '.pl -O -10,-10 '
      command = fmtstr('$clip stats {} -10,-10 -n 2.5 -l {} {}', montOpt, length,
                       dataName + '_fixed.st')

      # Run clip and extract the summary lines
      clipLines = runClipStats(command, '_fixed', 'fixed')
      if not clipLines:
         return 1
      prnLog(' ')
      for line in clipLines:
         if 'all' in line or 'extreme' in line:
            prnLog(line)
      prnLog(' ')

      # Use fixed stack
      if useFileAsReplacement(dataName + '_fixed.st', dataName + '.st', True, False):
         return 1

      # See if there is already an archive file to rename and find next number for that
      compName = dataName + '_xray.st.gz'
      if os.path.exists(compName):
            compList1 = glob.glob(compName + '.[0-9]')
            compList2 = glob.glob(compName + '.[0-9][0-9]')
            compList1.sort()
            compList2.sort()
            compList = compList1 + compList2
            nextNum = 1
            if len(compList):
               nextNum = int(os.path.splitext(compList[-1])[1][1:]) + 1
            try:
               os.rename(compName, compName + '.' + str(nextNum))
            except OSError:
               abortSet('Error renaming ' + compName + ' before archiving again')
               return 1

      # Run archiveorig
      if lookupDirective(runtimePrefix + 'Preprocessing', 'archiveOriginal', 0, 
                         BOOL_VALUE):
         prnLog('Archiving original stack as compressed difference file', flush=True)
         if writeTextFileReportErr('archiveorig' + axisCom,
                                   ['$archiveorig -d ' + dataName + '.st']):
            return 1
         err = runOneProcess('archiveorig' + axisCom)
         cleanupFiles(['archiveorig' + axisCom])
         if err:
            return 1

   # Possibly a stopgap: look for low-count views at end of series and exclude them
   if not ifMontage and needStep(1) and analyzeSDsAdjustExcludes(clipLines):
      return 1
         
   # coarse alignment
   if needStep(2) and runOneProcess('xcorr' + axisCom, message = 'Finding coarse ' + \
                                       'alignment by cross-correlation with Tiltxcorr'):
      return 1

   # Get the tiltalign file regardless, since it will be operated on
   taLines = readTextFile('align' + axisCom)
   if not taLines:
      return 1

   # Get the number of surfaces from directives in case it changed, fall back to align.com
   numSurfaces = lookupDirective(comPrefix + 'align', 'tiltalign.SurfacesToAnalyze', 0,
                                 INT_VALUE)
   if numSurfaces == None:
      numSurfaces = optionValue(taLines, 'SurfacesToAnalyze', INT_VALUE, numVal = 1)
      if numSurfaces == None:
         abortSet('Failed to find SurfacesToAnalyze in align' + axisCom)
   if numSurfaces <= 0:
      abortSet('SurfacesToAnalyze is 0 or negative in directives or in align' + axisCom)
      return 1

   if fiducialless or patchTrack:
      numSurfaces = 1
   
   # For fiducialless, make up the final xf
   if fiducialless:
      if fidlessFileOperations(taLines):
         return 1

   # Otherwise do many things
   else:

      # Make prealigned stack
      (comRoot, process) = comAndProcessForAlignedStack('pre')
      if needStep(3) and runOneProcess(comRoot + axisCom, message =
                                       'Making coarse aligned stack'):
         return 1

      # Patch tracking
      if needStep(4) and patchTrack:
         if runPatchTracking():
            return 1

      # Otherwise various ways of getting a fiducial model
      else:
         if makeSeedAndTrack(taLines):
            return 1

      # Tilt alignment needed if aligned stack or reconstruction being made
      if endingStep >= 5 and startingStep <= 14 and runTiltalign(taLines):
         return 1

      # Iterate patch tracking with angle offset now that it is known, if desired
      if lookupDirective(patchTrackText, 'adjustTiltAngles', 0, BOOL_VALUE) and \
             needStep(4) and patchTrack:
         sedcom = sedDelAndAdd('AngleOffset', totalDelTilt, 'SizeOfPatchesXandY')
         if modifyWriteAndRunCom('xcorr_pt' + axisCom, sedcom, message = fmtstr(
               'Running patch tracking again with angle offset of {:.1f}', totalDelTilt)):
            return 1
         if (runTiltalign(taLines)):
            return 1

   # Positioning
   reportReachedStep(6)
   if needStep(7) and positionTomogram():
      return 1
   
   # Make aligned stack
   reportReachedStep(7)
   if makeAlignedStack(0):
      return 1
         
   # Do CTF plotter step (tests need, sets correctCTF global)
   if CTFPlotAlignedStack():
      return 1

   # Set up the tilt com file now that output size is known and montage frame data set
   if endingStep >= detect3DstepNum and startingStep <= 14 and modifyTiltComFile(0):
      return 1

   # Do 3D gold detection (tests need, sets eraseGold global)
   if detectGoldIn3D():
      return 1
   
   # Optionally CTF correct the stack
   reportReachedStep(detect3DstepNum)
   if needStep(ctfCorrStepNum) and correctCTF and CTFCorrectAlignedStack():
      return 1

   # Optionally erase gold
   if needStep(eraseStepNum) and eraseGold and eraseGoldInAlignedStack():
      return 1

   # Optionally filter
   if filterAlignedStack():
      return 1

   # Make the reconstruction
   if needStep(14) and generateTomogram():
      return 1

   # Run trimvol on full data set or at axis level if directive for it
   if ((not dualAxis and needStep(trimStepNum)) or (dualAxis and needStep(14.5))) and \
          trimVolume():
      return 1

   # Run NAD on full data set only
   if not dualAxis and needStep(nadStepNum) and runNAD():
      return 1
   
   return 0


# Or run the steps for combine, return on error or when done
def runCombine():
   if needStep(15) and setupCombine():
      return

   if needStep(16) and initialCombineMatch():
      return

   if alignAndCombineAxes():
      return

   if needStep(trimStepNum) and trimVolume():
      return

   if needStep(nadStepNum):
      runNAD()

   
#### MAIN PROGRAM  ####
#
# load System Libraries
import os, sys, shutil, math, csv, re, time, datetime, platform

#
# Setup runtime environment
if os.getenv('IMOD_DIR') != None:
   sys.path.insert(0, os.path.join(os.environ['IMOD_DIR'], 'pylib'))
   from imodpy import *
   addIMODbinIgnoreSIGHUP()
else:
   sys.stdout.write(prefix + " IMOD_DIR is not defined!\n")
   sys.exit(1)

#
# load IMOD Libraries
from pip import *
from pysed import *

# Fallbacks from ../manpages/autodoc2man 3 1 batchruntomo
options = ["directive:DirectiveFile:FNM:", "root:RootName:FNM:",
           "current:CurrentLocation:FNM:", "deliver:DeliverToDirectory:FN:",
           "one:ProcessOneAxis:I:", "cpus:CPUMachineList:CH:",
           "single:SingleOnFirstCPU:B:", "gpus:GPUMachineList:CH:", "nice:NiceValue:I:",
           "limit:LimitLocalThreads:I:", "remote:RemoteDirectory:FN:",
           "check:CheckFile:FN:", "email:EmailAddress:CH:", "SMTP:SMTPserver:CH:",
           "validation:ValidationType:I:", "start:StartingStep:F:", "end:EndingStep:F:",
           "first:StartForFirstSetOnly:B:", "use:UseExistingAlignment:B:",
           "exit:ExitOnError:B:", "etomo:EtomoDebug:I:", ":PID:B:"]

copyPrefix = 'setupset.copyarg.'
setupPrefix = 'setupset.'
runtimePrefix = 'runtime.'
comPrefix = 'comparam.'
scopeTmplText = setupPrefix + 'scopeTemplate'
userTmplText = setupPrefix + 'userTemplate'
sysTmplText = setupPrefix + 'systemTemplate'
dataDirText = setupPrefix + 'datasetDirectory'
rootNameText = copyPrefix + 'name'
scanHeadText = setupPrefix + 'scanHeader'
patchTrackText = runtimePrefix + 'PatchTracking'
autoSeedText = runtimePrefix + 'SeedFinding'
combinePrefix = runtimePrefix + 'Combine'
setupBname = 'laterbsetup.com'
localBatchCopy = 'batchDirective.adoc'
proChunkCheckFile = 'processchunks.cmds'
montFrameData = 10 * [0]
suppressAbort = False
altExtension = 'mrc'
userTemplateDir = ''
summaryMessage = ''
ctfPlotStepNum = 9
detect3DstepNum = 10
ctfCorrStepNum = 11
eraseStepNum = 12
trimStepNum = 20
nadStepNum = 21
finalStepNum = 21

# Defaults
dfltDarkExcludeFraction = 0.33
dfltDarkExcludeRatio = 0.17
dfltMatchAtoBratio = 0.9
dfltCombineNumScales = 4
dfltCombineBoxSize = 32
dfltSampleThickness = 500
positionBinningTarget = 512
dfltPosThicknesses = (250, 400, 500, 600)
sizesForPosThicknesses = (0, 512, 1024, 2048)
dfltExtraWarpTargets = '0.4,0.45'
dfltFinalPatchSize = 'E'
solvematchMinFids = 8
solvematchMinEachSide = 3
solvematchMinSideRatio = 0.2
useFallbackRatio = 0.4
useVolMatch = -1
fb3dOptimalBinnedSize = 5.
fb3dMinBinnedSize = 4.

logFile = None
finalRetVal = 0
finishSetAndQuit = False
latestMessages = []
direcFileErrorNames = ['scope template', 'system template', 'user template',
                       'batch directive']

# List of coms where the runner is handling messages, and the standard tags for messages
handlingMessages = ['autofidseed', 'transferfid', 'track', 'align', 'solvematch',
                    'autopatchfit', 'dualvolmatch']
standardTags = [('ERROR:', 0), ('WARNING:', 0)]

# This handles the problem with # being lost as a comment in standard input
PipForbidComments('CPUMachineList', 'cpus', False)

(opts, nonopts) = PipReadOrParseOptions(sys.argv, options, progname, 1, 1, 0)
os.environ['PIP_PRINT_ENTRIES'] = '0'

doPID = PipGetBoolean('PID', 0)
printPID(doPID)

# Get the directive file names
numByArg = PipNumberOfEntries('DirectiveFile')
numSets = nonopts + numByArg
dirFiles = []
if not numSets:
   exitError('You must enter at least one directive file')
for ind in range(numSets):
   if ind < numByArg:
      dfile = PipGetString('DirectiveFile', '')
   else:
      dfile = PipGetNonOptionArg(ind)
   if not os.path.exists(dfile):
      exitError('Directive file ' + dfile + ' does not exist')
   dirFiles.append(dfile)

# Get current directory and delivery directory
currentDirs = []
numCurrent = PipNumberOfEntries('CurrentLocation')
for ind in range(numCurrent):
   currentDirs.append(PipGetString('CurrentLocation', ''))
deliverDir = PipGetString('DeliverToDirectory', '')
if deliverDir and numCurrent != 1 and numCurrent != numSets:
   exitError('The -current option must be entered either once, or once per data set, ' +\
                'if -deliver is entered')

# Get the root names if any
numRootOpts = PipNumberOfEntries('RootName')
rootByOption = []
for ind in range(numRootOpts):
   rootByOption.append(PipGetString('RootName', ''))

# Check validity of these entries and boost the directive file list
if numRootOpts and numSets > 1 and numSets != numRootOpts:
   exitError('If you enter root names, you must enter either one directive file or' + \
             ' one per root name')
if numRootOpts:
   for ind in range(numSets, numRootOpts):
      dirFiles.append(dirFiles[0])
   numSets = numRootOpts

if not deliverDir and (numRootOpts or numCurrent) and numCurrent != numSets:
   exitError('The -current option must be entered for each data set')

# Get other options and current directory
startingDir = os.getcwd()

# For CPU's, validate the number if it is just a number, then parse the list and add up
# the values after # if any, set flag for parallel processing = # of cores
cpuList = PipGetString('CPUMachineList', '')
localName = (platform.node().split('.'))[0]
parallelCPU = 0
mostCPUs = 0
topCPUmachine = '1'
topCpuLimit = 1
localCpuLimit = 1
firstCpuLimit = 1
if '#' in cpuList:
   prnstr('WARNING: The # sign should not be used in the -cpus entry; use : instead')
if cpuList != '':
   localCpuLimit = 0
   firstCpuLimit = 0
   try:
      parallelCPU = int(cpuList)
      localCpuLimit = parallelCPU
      firstCpuLimit = parallelCPU
      topCpuLimit = parallelCPU
      if parallelCPU < 1 or parallelCPU > 128:
         exitError('A number of cores entered with -cpus must be between 1 and 128')
   except ValueError:
      for machine in cpuList.split(','):
         msplit = machine.replace('#', ':').split(':')
         if len(msplit) > 2:
            exitError('A machine name cannot be followed by two : or # signs')
         if len(msplit) < 2:
            numCPU = 1
         else:
            try:
               numCPU = int(msplit[1])
               if numCPU < 1:
                  exitError('The value after : or # is less than 1 in ' + machine)
            except ValueError:
               exitError('Failed to convert value after : or # to integer in ' + machine)
         parallelCPU += numCPU
         if msplit[0] == 'localhost' or (msplit[0].split('.'))[0] == localName:
            localCpuLimit += numCPU
         if numCPU > mostCPUs:
            mostCPUs = numCPU
            topCPUmachine = msplit[0]
            topCpuLimit = numCPU
         if not firstCpuLimit:
            firstCpuLimit = numCPU

# After all that, replace the #'s in the list that will get used, and accept an option
# to set or revise the limit on local cores, and if it is high enough, then revise the
# machine with most CPUs
cpuList = cpuList.replace('#', ':')
localLimit = PipGetInteger('LimitLocalThreads', 0)
if localLimit < 0 or localLimit > 128:
   exitError('The limit on number of local threads must be between 1 and 128')
if localLimit:
   localCpuLimit = localLimit
   if localLimit > topCpuLimit:
      topCPUmachine = 'localhost'
      topCpuLimit = localLimit

# For GPU's, set useGPU if entered, insist a number is 1, and set flag for parallel GPU
# if there is an actual machine list to number of GPUs, adding up entries 
# with : separators.  Here keep parallelGPU = 1 if
# it is running without splitting on a single remote machine
gpuList = PipGetString('GPUMachineList', '')
useGPU = gpuList != ''
parallelGPU = 0

if useGPU:
   try:
      useGPU = int(gpuList)
      if useGPU != 1:
         exitError('The entry for -gpus must be 1 to use just the local GPU')
   except ValueError:
      for machine in gpuList.split(','):
         msplit = machine.split(':')
         parallelGPU += max(1, len(msplit) - 1)

niceness = PipGetInteger('NiceValue', 15)
remoteStartDir = PipGetString('RemoteDirectory', '')
doOneAxis = PipGetInteger('ProcessOneAxis', 0)
startingStep = PipGetFloat('StartingStep', 0.)
endingStep = PipGetFloat('EndingStep', 10000000.)
firstStart = PipGetBoolean('StartForFirstSetOnly', 0)
skipTiltalign = PipGetBoolean('UseExistingAlignment', 0)
exitOnError = PipGetBoolean('ExitOnError', 0)
etomoDebug = PipGetInteger('EtomoDebug', 0)
useFirstCPUforSingle = PipGetBoolean('SingleOnFirstCPU',0)
if not firstStart and startingStep > 100:
   prnstr('WARNING: Entering a starting step above 100 has no effect without ' +\
             '-first option')
   while startingStep > 100:
      startingStep -= 100
if skipTiltalign and (startingStep <= 5.005 or \
                         (startingStep > 99.995 and startingStep <= 105.005)):
   exitError('You cannot use an existing alignment when you start before the ' +\
                'alignment step')
   
validation = PipGetInteger('ValidationType', 0)
remoteDataDir = ''
emailAddress = PipGetString('EmailAddress', '')
SMTPserver = PipGetString('SMTPserver', 'localhost')
if emailAddress:
   if pyVersion < 250:
      emailAddress = ''
      prnstr('WARNING: No emails will be sent; the Python version must be 2.5 or ' + \
                'higher to send emails')
   else:
      import smtplib
      from email.mime.text import MIMEText

# Set up check file
checkFile = PipGetString('CheckFile', '')
if checkFile:
   checkFile = imodAbsPath(checkFile)
else:
   checkFile = imodAbsPath(os.path.join(startingDir, progname + '.' +
                                    str(os.getpid()) + '.input'))
if validation <= 0:
   prnstr('To quit all processing, place a Q in the file: ' + checkFile)
if os.path.exists(checkFile):
   cleanupFiles([checkFile])

baseComDict = {}
validComDict = {}
validRunDict = {}
validOtherDict = {}
fileType = 'directive'

if validation >= 0:
   validateFile = os.path.join(os.path.join(os.environ['IMOD_DIR'], 'com'), \
       'directives.csv')
   if not os.path.exists(validateFile):
      exitError('Cannot find file for validating directives, ' + validateFile)

   processValidationFile()
   if validation > 1:
      fileType = 'template'

# Start looping on the data sets
for dfileInd in range(numSets):

   # These need to be initialized for abortSet to work right
   dualAxis = False
   axisLet = None
   setName = '# ' + str(dfileInd + 1)

   closeLogFile()
   dfile = dirFiles[dfileInd]
   axisNum = 0

   # Check for an F in the check file before going on
   # No need to remove processchunks check file, it takes care of it itself
   checkForQuit()
   if finishSetAndQuit:
      prnstr('Exiting after finishing dataset as requested')
      sys.exit(0)

   os.chdir(startingDir)
   allDirectives = [{}, {}, {}, {}]
   absDirectiveFile = imodAbsPath(dfile)
   if readDirectiveOrTemplate(dfile, BatInd):
      continue

   prnstr(fmtstr('Beginning to process {} file # {} : {}', fileType, dfileInd + 1, dfile))
   startTime = time.time()

   # If validating a single template file, do not process it, just run the checks
   if validation > 1:
      if not checkAllDirectives('template'):
         prnstr('Directives all seem OK in that file')
      continue
   
   # Get essential setup items from directives
   if scanSetupDirectives():
      continue

   if validation >= 0:
      if checkAllDirectives():
         continue
      if validation > 0:
         prnstr('Directives all seem OK in that file')
         continue

   # Deliver stacks to dataset directory, from the source current dir or the one for this
   # data set
   if deliverDir:
      deliverFromDir = currentDirs[min(dfileInd, len(currentDirs) - 1)]
      if dualAxis and doOneAxis < 2 and deliverStack('a'):
         continue
      if dualAxis and doOneAxis != 1 and deliverStack('b'):
         continue
      if not dualAxis and deliverStack(''):
         continue

   # If there is a remote directory, need to shift it to the dataset dir
   if remoteStartDir:
      absDataDir = imodAbsPath(datasetDir)
      prefix = os.path.commonprefix([startingDir, absDataDir])
      remoteDataDir = ''
      if prefix and absDataDir.startswith(prefix) and startingDir.startswith(prefix):
         startRemnant = startingDir[len(prefix):]
         dataRemnant = datasetDir[len(prefix):]
         ind = remoteStartDir.find(startRemnant)
         if ind > 0:
            remoteDataDir = os.path.normpath(os.path.join(remoteStartDir[0:ind], \
                                                             dataRemnant))
      if not remoteDataDir:
         abortSet('Cannot translate remote directory entry ' + remoteStartDir + \
                     ' to work with ' + datasetDir)
         continue

   try:
      os.chdir(datasetDir)
   except OSError:
      abortSet('Error changing to directory ' + datasetDir)
      continue

   # Open log file now
   try:
      logFile = open('batchruntomo.log', 'a')
      prnstr('\nBatchruntomo started on data set, ' + datetime.datetime.now().ctime(),
             file = logFile)
   except IOError:
      prnstr('WARNING: Failed to open or write to log file in data set directory')
      try:
         logFile.close()
         logFile = None
      except:
         pass
   
   # Check existence of file(s)
   stack = setName + '.'
   numAxes = 1
   if dualAxis:
      numAxes = 2
      stack = setName + 'a.'
   if checkRenameStack(stack):
      continue
   if dualAxis and doOneAxis != 1 and checkRenameStack(setName + 'b.'):
      continue
   stack += 'st'

   # Get pixel size if scanHeader set
   if scanHeader and not pixelSize:
      try:
         px = getmrcpixel(stack)
         pixelSize = px / 10.
      except ImodpyError:
         reportImodError('Error getting pixel size from ' + stack)
         continue

   prnLog('Starting data set ' + setName + '   at ' + \
             datetime.datetime.now().strftime('%H:%M:%S'))
   prnLog('', flush = True)

   if startingStep <= 0 and not (dualAxis and doOneAxis > 1):

      # Run etomo for setup and try to report errors
      failed = False
      errlog = ''
      try:
         comline = 'etomo --fromBRT --directive "' + absDirectiveFile + '"'
         if etomoDebug:
            comline += ' --debug ' + str(etomoDebug)
         if parallelCPU > 1:
            comline += ' --cpus "' + cpuList + '"'
         if gpuList != '':
            comline += ' --gpus "' + gpuList + '"'
         etlines = runcmd(comline)
         for l in etlines:
            prnLog(l.rstrip())
            ind = l.find('with log in')
            if ind > 0:
               errlog = l[ind + 11:].strip()
      except ImodpyError:
         failed = True
         for l in getErrStrings():
            ind = l.find('check:')
            if ind > 0:
               errlog = l[ind + 7:].strip()


      if errlog:
         if '/' in errlog or '\\' in errlog:
            try:
               shutil.copy(errlog, '.')
            except Exception:
               prnLog('WARNING: failed to copy ' + errlog + ' to dataset directory')

         loglines = readTextFile(errlog, None, True)
         if isinstance(loglines, str):
            prnLog('WARNING: Error ' + loglines)
         else:
            printTaggedMessages(loglines, [('INFO:', 1), ('LOG:', 1)])
            err = 0
            for line in loglines:
               if 'Pixel spacing was set in FEI file' in line:
                  err = fixAllSuppliedModelHeaders()
                  break

            if err:
               prnLog('Cannot proceed with this data set')
               continue
            
      else:
         if failed:
            prnLog('Running etomo failed, no etomo error log available')
         else:
            prnLog('Cannot access an error log from running etomo')
      if failed:
         reportImodError('etomo setup failed, cannot proceed with this data set')
         continue

   fidSizePix = fidSizeNm / pixelSize
   haveAaxisAFSbound = False
   
   # Loop on the axes.  axisInd is 0 or 1, axisNum is 0 for single, 1/2 for a/b
   for axisInd in range(numAxes):
      if endingStep <= 0 or (dualAxis and ((axisInd and doOneAxis == 1) or 
                                           (not axisInd and doOneAxis > 1))):
         continue
      axisLet = ''
      if dualAxis:
         axisNum = axisInd + 1
         axisLet = 'a'
         if axisInd:
            axisLet = 'b'
         prnLog('Starting axis ' + axisLet.upper())

      if axisInd and doOneAxis > 1 and os.path.exists(setupBname):
         if runOneProcess(setupBname, message =
                          'Doing setup tasks now that second axis is present'):
            startingStep = 0
            continue
            
      dataName = setName + axisLet
      axisCom = axisLet + '.com'
      while startingStep > 100:
         startingStep -= 100.
         continue
      if runOneAxis():
         if firstStart:
            startingStep = 0
            skipTiltalign = 0
         continue
      if firstStart:
         startingStep = 0
         skipTiltalign = 0
      if dualAxis:
         message = 'Completed axis ' + axisLet.upper() + ' of dataset ' + setName
      else:
         message = 'Completed dataset ' + setName
      if endingStep < finalStepNum:
         endPrint = int(round(endingStep))
         if math.fabs(endPrint - endingStep) > 0.005:
            endPrint = endingStep
         message += fmtstr(' through step {}', endPrint)
      if not dualAxis:
         (minutes, seconds, frac) = elapsedComponents(startTime);
         message += fmtstr('  in {:02d}:{:02d}.{}', minutes, seconds, frac)
      prnLog(message)
      summaryMessage += message + '\n'

   # Try to combine dual axis dataset
   if dualAxis:
      axisNum = 0
      axisLet = 'a'
      axisInd = 2
      dataName = setName
      runCombine()
      (minutes, seconds, frac) = elapsedComponents(startTime);
      prnLog(fmtstr('Completed dataset {}  in {:02d}:{:02d}.{}', setName, minutes,
                    seconds, frac))
      
   closeLogFile()
   prnLog('', flush = True);

sendEmail('Batchruntomo finished all data sets', summaryMessage)
sys.exit(finalRetVal)
